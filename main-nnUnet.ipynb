{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (5.24.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from plotly) (9.0.0)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from plotly) (23.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"%pip install huggingface_hub\n",
    "%pip install git+https://github.com/facebookresearch/segment-anything-2/\n",
    "%pip install -r https://raw.githubusercontent.com/facebookresearch/segment-anything-2/main/requirements.txt\"\"\"\n",
    "%pip install plotly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.16 (you have 1.4.14). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pydicom as dicom\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "from skimage import io \n",
    "from PIL import Image, ImageOps\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import glob\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import imageio\n",
    "import sys\n",
    "\n",
    "import concurrent.futures\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "import random\n",
    "from glob import glob\n",
    "import os, shutil\n",
    "tqdm.pandas()\n",
    "import time\n",
    "import copy\n",
    "import joblib\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "from IPython import display as ipd\n",
    "\n",
    "# visualization\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, StratifiedGroupKFold\n",
    "\n",
    "# PyTorch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "\n",
    "import timm\n",
    "\n",
    "# Albumentations for augmentations\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import rasterio\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# For colored terminal text\n",
    "from colorama import Fore, Back, Style\n",
    "c_  = Fore.GREEN\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For descriptive error messages\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook Structure:\n",
    "    Load in data\n",
    "        - Load in csv files for default and 'improved' data\n",
    "        - Combine the default and additional dataframes\n",
    "        - Add filenames to the dataframes\n",
    "    \n",
    "    Preprocess imgs\n",
    "        - Load in dicom stacks\n",
    "        - Crop nessecary imgs\n",
    "        - Save all as png\n",
    "\n",
    "    Create Pytorch Dataset\n",
    "\n",
    "    Create model\n",
    "        - Download pretrained resnet18\n",
    "        - Change the output size of the resnet18 model\n",
    "\n",
    "    Train model\n",
    "        - N epochs\n",
    "        - Save the weights\n",
    "    \n",
    "    Preprocess Test Imgs\n",
    "\n",
    "\n",
    "    Create Test Pytorch Dataset\n",
    "\n",
    "\n",
    "    Use Model To Predict Severity\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################################################\n",
    "##################################################\"\"\"LOAD IN DATA\"\"\"###############################################################\n",
    "###################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>series_description</th>\n",
       "      <th>instance_number</th>\n",
       "      <th>condition</th>\n",
       "      <th>level</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>Sagittal_T2_STIR</td>\n",
       "      <td>8</td>\n",
       "      <td>spinal_canal_stenosis</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>322.831858</td>\n",
       "      <td>227.964602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>Sagittal_T2_STIR</td>\n",
       "      <td>8</td>\n",
       "      <td>spinal_canal_stenosis</td>\n",
       "      <td>l2_l3</td>\n",
       "      <td>320.571429</td>\n",
       "      <td>295.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>Sagittal_T2_STIR</td>\n",
       "      <td>8</td>\n",
       "      <td>spinal_canal_stenosis</td>\n",
       "      <td>l3_l4</td>\n",
       "      <td>323.030303</td>\n",
       "      <td>371.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>Sagittal_T2_STIR</td>\n",
       "      <td>8</td>\n",
       "      <td>spinal_canal_stenosis</td>\n",
       "      <td>l4_l5</td>\n",
       "      <td>335.292035</td>\n",
       "      <td>427.327434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>Sagittal_T2_STIR</td>\n",
       "      <td>8</td>\n",
       "      <td>spinal_canal_stenosis</td>\n",
       "      <td>l5_s1</td>\n",
       "      <td>353.415929</td>\n",
       "      <td>483.964602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48687</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>4237840455</td>\n",
       "      <td>Sagittal_T1</td>\n",
       "      <td>11</td>\n",
       "      <td>left_neural_foraminal_narrowing</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>219.465940</td>\n",
       "      <td>97.831063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48688</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>4237840455</td>\n",
       "      <td>Sagittal_T1</td>\n",
       "      <td>12</td>\n",
       "      <td>left_neural_foraminal_narrowing</td>\n",
       "      <td>l2_l3</td>\n",
       "      <td>205.340599</td>\n",
       "      <td>140.207084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48689</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>4237840455</td>\n",
       "      <td>Sagittal_T1</td>\n",
       "      <td>12</td>\n",
       "      <td>left_neural_foraminal_narrowing</td>\n",
       "      <td>l3_l4</td>\n",
       "      <td>202.724796</td>\n",
       "      <td>181.013624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48690</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>4237840455</td>\n",
       "      <td>Sagittal_T1</td>\n",
       "      <td>12</td>\n",
       "      <td>left_neural_foraminal_narrowing</td>\n",
       "      <td>l4_l5</td>\n",
       "      <td>202.933333</td>\n",
       "      <td>219.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48691</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>4237840455</td>\n",
       "      <td>Sagittal_T1</td>\n",
       "      <td>12</td>\n",
       "      <td>left_neural_foraminal_narrowing</td>\n",
       "      <td>l5_s1</td>\n",
       "      <td>211.813953</td>\n",
       "      <td>259.534884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48692 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         study_id   series_id series_description  instance_number  \\\n",
       "0         4003253   702807833   Sagittal_T2_STIR                8   \n",
       "1         4003253   702807833   Sagittal_T2_STIR                8   \n",
       "2         4003253   702807833   Sagittal_T2_STIR                8   \n",
       "3         4003253   702807833   Sagittal_T2_STIR                8   \n",
       "4         4003253   702807833   Sagittal_T2_STIR                8   \n",
       "...           ...         ...                ...              ...   \n",
       "48687  4290709089  4237840455        Sagittal_T1               11   \n",
       "48688  4290709089  4237840455        Sagittal_T1               12   \n",
       "48689  4290709089  4237840455        Sagittal_T1               12   \n",
       "48690  4290709089  4237840455        Sagittal_T1               12   \n",
       "48691  4290709089  4237840455        Sagittal_T1               12   \n",
       "\n",
       "                             condition  level           x           y  \n",
       "0                spinal_canal_stenosis  l1_l2  322.831858  227.964602  \n",
       "1                spinal_canal_stenosis  l2_l3  320.571429  295.714286  \n",
       "2                spinal_canal_stenosis  l3_l4  323.030303  371.818182  \n",
       "3                spinal_canal_stenosis  l4_l5  335.292035  427.327434  \n",
       "4                spinal_canal_stenosis  l5_s1  353.415929  483.964602  \n",
       "...                                ...    ...         ...         ...  \n",
       "48687  left_neural_foraminal_narrowing  l1_l2  219.465940   97.831063  \n",
       "48688  left_neural_foraminal_narrowing  l2_l3  205.340599  140.207084  \n",
       "48689  left_neural_foraminal_narrowing  l3_l4  202.724796  181.013624  \n",
       "48690  left_neural_foraminal_narrowing  l4_l5  202.933333  219.733333  \n",
       "48691  left_neural_foraminal_narrowing  l5_s1  211.813953  259.534884  \n",
       "\n",
       "[48692 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"rsna-2024-lumbar-spine-degenerative-classification/train.csv\")\n",
    "train_label_coordinates = pd.read_csv(\"rsna-2024-lumbar-spine-degenerative-classification/train_label_coordinates.csv\")\n",
    "train_series_descriptions = pd.read_csv(\"rsna-2024-lumbar-spine-degenerative-classification/train_series_descriptions.csv\")\n",
    "test_series_description  = pd.read_csv(\"rsna-2024-lumbar-spine-degenerative-classification/test_series_descriptions.csv\")\n",
    "coords = pd.read_csv(\"coords_rsna_improved.csv\")\n",
    "\n",
    "train_labels = pd.merge(train_series_descriptions, train_label_coordinates, on = ['study_id', 'series_id'])\n",
    "\n",
    "#Align formatting with the train.csv file as well as the sample submission\n",
    "condition = train_labels['condition'].to_numpy()\n",
    "reformatted_condition = np.array([cond.lower().replace(' ', '_') for cond in condition])\n",
    "train_labels.iloc[::, 4] = reformatted_condition\n",
    "\n",
    "level = train_labels['level'].to_numpy()\n",
    "reformatted_level = np.array([l.lower().replace('/', '_') for l in level])\n",
    "train_labels.iloc[::, 5] = reformatted_level\n",
    "\n",
    "series_description = train_labels['series_description'].to_numpy()\n",
    "reformatted_sd = np.array([d.replace(' ', '_').replace('/', '_') for d in series_description])\n",
    "train_labels.iloc[::, 2] = reformatted_sd\n",
    "\n",
    "def is_nan(value):\n",
    "    return pd.isna(value)\n",
    "\n",
    "def clean_nan_values(data):\n",
    "    for index, row in data.iterrows():\n",
    "        for i in range(len(row)):\n",
    "            if is_nan(row[i]):\n",
    "                row[i] = \"Normal/Mild\"\n",
    "    return data\n",
    "\n",
    "train = clean_nan_values(train)\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spinal_canal_columns = train.filter(like='spinal_canal').columns\n",
    "train[spinal_canal_columns] = train[spinal_canal_columns].fillna('Normal/Mild')\n",
    "\n",
    "\n",
    "def fill_nan_left_and_right(df, column):\n",
    "    target_columns = df.filter(like=column).columns \n",
    "    null_rows = df[df[target_columns].isnull().any(axis=1)]\n",
    "    for level in ['l1_l2', 'l2_l3', 'l3_l4', 'l4_l5', 'l5_s1']:\n",
    "        left_col = f\"left_{column}_{level}\"\n",
    "        right_col = f\"right_{column}_{level}\"\n",
    "        for index, row in null_rows.iterrows():\n",
    "            if pd.isna(row[left_col]) and pd.isna(row[right_col]):\n",
    "                df.at[index, left_col] = 'Normal/Mild'\n",
    "                df.at[index, right_col] = 'Normal/Mild'\n",
    "            \n",
    "            elif pd.isna(row[right_col]):\n",
    "                df.at[index, right_col] = row[left_col]\n",
    "            \n",
    "            elif pd.isna(row[left_col]):\n",
    "                df.at[index, left_col] = row[right_col]\n",
    "            else:\n",
    "                continue\n",
    "    return df\n",
    "train = fill_nan_left_and_right(train, 'neural_foraminal_narrowing')\n",
    "train = fill_nan_left_and_right(train, 'subarticular_stenosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>instance_number</th>\n",
       "      <th>condition</th>\n",
       "      <th>level</th>\n",
       "      <th>relative_x</th>\n",
       "      <th>relative_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3996069892</td>\n",
       "      <td>10996</td>\n",
       "      <td>13</td>\n",
       "      <td>Left Neural Foraminal Narrowing</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.521148</td>\n",
       "      <td>0.325282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3996069892</td>\n",
       "      <td>10996</td>\n",
       "      <td>6</td>\n",
       "      <td>Right Neural Foraminal Narrowing</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.516856</td>\n",
       "      <td>0.319701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3996069892</td>\n",
       "      <td>10996</td>\n",
       "      <td>12</td>\n",
       "      <td>Left Neural Foraminal Narrowing</td>\n",
       "      <td>l2_l3</td>\n",
       "      <td>0.493773</td>\n",
       "      <td>0.400966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3996069892</td>\n",
       "      <td>10996</td>\n",
       "      <td>6</td>\n",
       "      <td>Right Neural Foraminal Narrowing</td>\n",
       "      <td>l2_l3</td>\n",
       "      <td>0.504032</td>\n",
       "      <td>0.385531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3996069892</td>\n",
       "      <td>10996</td>\n",
       "      <td>12</td>\n",
       "      <td>Left Neural Foraminal Narrowing</td>\n",
       "      <td>l3_l4</td>\n",
       "      <td>0.487331</td>\n",
       "      <td>0.475040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58730</th>\n",
       "      <td>916362094</td>\n",
       "      <td>4294540297</td>\n",
       "      <td>10</td>\n",
       "      <td>Spinal Canal Stenosis</td>\n",
       "      <td>l3_l4</td>\n",
       "      <td>0.511282</td>\n",
       "      <td>0.571751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58731</th>\n",
       "      <td>916362094</td>\n",
       "      <td>4294540297</td>\n",
       "      <td>-1</td>\n",
       "      <td>Spinal Canal Stenosis</td>\n",
       "      <td>l4_l5</td>\n",
       "      <td>0.308594</td>\n",
       "      <td>0.667969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58732</th>\n",
       "      <td>916362094</td>\n",
       "      <td>4294540297</td>\n",
       "      <td>9</td>\n",
       "      <td>Spinal Canal Stenosis</td>\n",
       "      <td>l4_l5</td>\n",
       "      <td>0.516697</td>\n",
       "      <td>0.671029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58733</th>\n",
       "      <td>916362094</td>\n",
       "      <td>4294540297</td>\n",
       "      <td>-1</td>\n",
       "      <td>Spinal Canal Stenosis</td>\n",
       "      <td>l5_s1</td>\n",
       "      <td>0.328125</td>\n",
       "      <td>0.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58734</th>\n",
       "      <td>916362094</td>\n",
       "      <td>4294540297</td>\n",
       "      <td>10</td>\n",
       "      <td>Spinal Canal Stenosis</td>\n",
       "      <td>l5_s1</td>\n",
       "      <td>0.534747</td>\n",
       "      <td>0.761282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58735 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         study_id   series_id  instance_number  \\\n",
       "0      3996069892       10996               13   \n",
       "1      3996069892       10996                6   \n",
       "2      3996069892       10996               12   \n",
       "3      3996069892       10996                6   \n",
       "4      3996069892       10996               12   \n",
       "...           ...         ...              ...   \n",
       "58730   916362094  4294540297               10   \n",
       "58731   916362094  4294540297               -1   \n",
       "58732   916362094  4294540297                9   \n",
       "58733   916362094  4294540297               -1   \n",
       "58734   916362094  4294540297               10   \n",
       "\n",
       "                              condition  level  relative_x  relative_y  \n",
       "0       Left Neural Foraminal Narrowing  l1_l2    0.521148    0.325282  \n",
       "1      Right Neural Foraminal Narrowing  l1_l2    0.516856    0.319701  \n",
       "2       Left Neural Foraminal Narrowing  l2_l3    0.493773    0.400966  \n",
       "3      Right Neural Foraminal Narrowing  l2_l3    0.504032    0.385531  \n",
       "4       Left Neural Foraminal Narrowing  l3_l4    0.487331    0.475040  \n",
       "...                                 ...    ...         ...         ...  \n",
       "58730             Spinal Canal Stenosis  l3_l4    0.511282    0.571751  \n",
       "58731             Spinal Canal Stenosis  l4_l5    0.308594    0.667969  \n",
       "58732             Spinal Canal Stenosis  l4_l5    0.516697    0.671029  \n",
       "58733             Spinal Canal Stenosis  l5_s1    0.328125    0.796875  \n",
       "58734             Spinal Canal Stenosis  l5_s1    0.534747    0.761282  \n",
       "\n",
       "[58735 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords = pd.read_csv('coords_rsna_improved.csv')\n",
    "\n",
    "coords = coords.drop(['side'], axis = 1)\n",
    "coords = coords.drop(coords.columns[0], axis=1)\n",
    "coords['level'] = [level.lower().replace('/', '_') for level in coords['level'].to_list()]\n",
    "\n",
    "coords = coords[['study_id', 'series_id', 'instance_number', 'condition', 'level', 'relative_x', 'relative_y']]\n",
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################################################\n",
    "###############################################\"\"\"PREPROCESS DATA\"\"\"###############################################################\n",
    "###################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Translate Coordinates.\"\"\"\n",
    "def load_dcm_img(dcm_path) -> np.ndarray:\n",
    "    dcm = dicom.dcmread(dcm_path)\n",
    "    img: np.ndarray = dcm.pixel_array\n",
    "    img = img.clip(np.percentile(img, 1), np.percentile(img, 99))\n",
    "    img = img - np.min(img)\n",
    "    img = img / np.max(img)\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def convert_to_8bit(x):\n",
    "    lower, upper = np.percentile(x, (1, 99))\n",
    "    x = np.clip(x, lower, upper)\n",
    "    x = x - np.min(x)\n",
    "    x = x / np.max(x)\n",
    "    return (x * 255).astype(\"uint8\")\n",
    "\n",
    "def load_dicom_stack(dicom_folder, plane, reverse_sort=False):\n",
    "    dicom_files = glob(os.path.join(dicom_folder, \"*.dcm\"))\n",
    "    if not dicom_files:\n",
    "        raise ValueError(f\"No DICOM files found in {dicom_folder}\")\n",
    "        \n",
    "    dicoms = [dicom.dcmread(f) for f in dicom_files]\n",
    "    plane_index = {\"sagittal\": 0, \"coronal\": 1, \"axial\": 2}[plane.lower()]\n",
    "    positions = np.asarray([float(d.ImagePositionPatient[plane_index]) for d in dicoms])\n",
    "\n",
    "    idx = np.argsort(-positions if reverse_sort else positions)\n",
    "    dicoms = [dicoms[i] for i in idx]\n",
    "    max_shape = max([d.pixel_array.shape for d in dicoms])\n",
    "\n",
    "    #Normalize the shape by padding with zeros or resizing\n",
    "    normalized_arrays, padding_array = [], []\n",
    "    for d in dicoms:\n",
    "        img = d.pixel_array.astype(\"float32\")\n",
    "        if img.shape != max_shape:\n",
    "            #Resize or pad the image to the max_shape\n",
    "            padded_img = np.zeros(max_shape, dtype=\"float32\")\n",
    "            padded_img[:img.shape[0], :img.shape[1]] = img\n",
    "            normalized_arrays.append(padded_img)\n",
    "\n",
    "            x_padding = max_shape[1] - img.shape[1]\n",
    "            y_padding = max_shape[0] - img.shape[0]\n",
    "            padding_array.append((x_padding // 2, y_padding // 2))\n",
    "        else:\n",
    "            normalized_arrays.append(img)\n",
    "            padding_array.append((0, 0))\n",
    "\n",
    "    array = np.stack(normalized_arrays)\n",
    "    ipp = np.asarray([d.ImagePositionPatient for d in dicoms]).astype(\"float\")[idx]\n",
    "\n",
    "    return {\n",
    "        \"array\": convert_to_8bit(array), \n",
    "        \"positions\": ipp, \n",
    "        \"pixel_spacing\": np.asarray(dicoms[0].PixelSpacing).astype(\"float\"),\n",
    "        \"padding_array\": padding_array\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMG_DIR = \"rsna-2024-lumbar-spine-degenerative-classification/train_images\"\n",
    "normal_tl = \"normal_train_labels.csv\"\n",
    "\n",
    "if os.path.exists(normal_tl) == False:\n",
    "    for study_folder_path in tqdm(os.listdir(TRAIN_IMG_DIR)):\n",
    "        series_folders = os.listdir(os.path.join(TRAIN_IMG_DIR, study_folder_path))\n",
    "        for idx, series_folder in enumerate(series_folders):\n",
    "            dcm_folder_path = os.path.join(TRAIN_IMG_DIR, study_folder_path, series_folder)\n",
    "\n",
    "            df = train_labels[train_labels[\"series_id\"] == int(series_folder)]\n",
    "            try:\n",
    "                series_desc = df[\"series_description\"].values[0]\n",
    "            except:\n",
    "                print(f\"Series description for series_id: {series_folder} not found! Skipping.\")\n",
    "                continue\n",
    "\n",
    "            plane = \"sagittal\" if series_desc != \"Axial T2\" else \"axial\"\n",
    "            dicom_data_3d = load_dicom_stack(dcm_folder_path, plane = plane)\n",
    "            padding_array = dicom_data_3d[\"padding_array\"]\n",
    "            \n",
    "            for i in range(len(df[\"x\"].to_list())):\n",
    "                x_pad, y_pad = padding_array[i]\n",
    "                df.iloc[i, df.columns.get_loc(\"x\")] = df.iloc[i, df.columns.get_loc(\"x\")] + x_pad\n",
    "                df.iloc[i, df.columns.get_loc(\"y\")] = df.iloc[i, df.columns.get_loc(\"y\")] + y_pad\n",
    "\n",
    "\n",
    "            pixel_spacing = dicom_data_3d[\"pixel_spacing\"]\n",
    "            img = dicom_data_3d[\"array\"][idx]\n",
    "            img_shape = img.shape\n",
    "\n",
    "            x_scale_factor = 224 / img_shape[1]\n",
    "            y_scale_factor = 224 / img_shape[0]\n",
    "\n",
    "            train_labels.loc[df.index, \"x\"] = df[\"x\"] * (x_scale_factor)\n",
    "            train_labels.loc[df.index, \"y\"] = df[\"y\"] * (y_scale_factor)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48692\n",
      "18114\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Verify Coordinates are between 0 and 224.\"\"\"\n",
    "print(len(train_labels))\n",
    "tl_in_lims = train_labels[(train_labels[\"x\"] >= 0) & (train_labels[\"x\"] <= 224) & (train_labels[\"y\"] >= 0) & (train_labels[\"y\"] <= 224)]\n",
    "print(len(tl_in_lims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48692\n",
      "   study_id   series_id series_description  instance_number  \\\n",
      "0   4003253   702807833   Sagittal_T2_STIR                8   \n",
      "1   4003253   702807833   Sagittal_T2_STIR                8   \n",
      "2   4003253   702807833   Sagittal_T2_STIR                8   \n",
      "3   4003253   702807833   Sagittal_T2_STIR                8   \n",
      "4   4003253   702807833   Sagittal_T2_STIR                8   \n",
      "5   4003253  1054713880        Sagittal_T1                4   \n",
      "6   4003253  1054713880        Sagittal_T1                4   \n",
      "7   4003253  1054713880        Sagittal_T1                5   \n",
      "8   4003253  1054713880        Sagittal_T1                6   \n",
      "9   4003253  1054713880        Sagittal_T1                6   \n",
      "\n",
      "                          condition  level           x           y  \n",
      "0             spinal_canal_stenosis  l1_l2  322.831858  227.964602  \n",
      "1             spinal_canal_stenosis  l2_l3  320.571429  295.714286  \n",
      "2             spinal_canal_stenosis  l3_l4  323.030303  371.818182  \n",
      "3             spinal_canal_stenosis  l4_l5  335.292035  427.327434  \n",
      "4             spinal_canal_stenosis  l5_s1  353.415929  483.964602  \n",
      "5  right_neural_foraminal_narrowing  l4_l5  187.961759  251.839388  \n",
      "6  right_neural_foraminal_narrowing  l5_s1  198.240918  285.613767  \n",
      "7  right_neural_foraminal_narrowing  l3_l4  187.227533  210.722753  \n",
      "8  right_neural_foraminal_narrowing  l1_l2  194.569790  127.755258  \n",
      "9  right_neural_foraminal_narrowing  l2_l3  191.632887  165.934990  \n"
     ]
    }
   ],
   "source": [
    "print(len(train_labels))\n",
    "print(train_labels.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(normal_tl):\n",
    "    train_labels = pd.read_csv(normal_tl)\n",
    "else:\n",
    "    train_labels.to_csv(normal_tl, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_img(img, pixel_spacing, new_spacing):\n",
    "    current_spacing = np.array(pixel_spacing, dtype=np.float32)\n",
    "    resize_factor = current_spacing / new_spacing\n",
    "    new_shape = np.round(img.shape * resize_factor).astype(int)\n",
    "    resampled_image = resize(img, new_shape, preserve_range=True, anti_aliasing=True)\n",
    "    return resampled_image\n",
    "\n",
    "def resize_img(img):\n",
    "    return resize(img, (224, 224), preserve_range=True, anti_aliasing=True)\n",
    "\n",
    "#def reduce_noise(img):\n",
    "    #return cv2.fastNlMeansDenoising(img, None, 5, 7, 21)\n",
    "\n",
    "def normalize_img(img):\n",
    "    return (img - np.min(img)) / (np.max(img) - np.min(img))\n",
    "\n",
    "def preprocess_img(img, pixel_spacing):\n",
    "    resampled_img = resample_img(img, pixel_spacing, (1.0, 1.0))\n",
    "    resized_img = resize_img(resampled_img)\n",
    "    #denoised_img = reduce_noise(resized_img)\n",
    "    normalized_img = normalize_img(resized_img)\n",
    "    return normalized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Functions which get the dicom info and use it to create a preprocessed img, whilst also scaling the coords correctly\"\"\"\n",
    "def save_img(img, filename, save_folder):\n",
    "    os.makedirs(save_folder, exist_ok = True)\n",
    "    imageio.imwrite(os.path.join(save_folder, filename), (img * 255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"train_png\") == False:\n",
    "    for study_folder_path in tqdm(os.listdir(TRAIN_IMG_DIR)):\n",
    "        series_folders = os.listdir(os.path.join(TRAIN_IMG_DIR, study_folder_path))\n",
    "        for series_folder in series_folders:\n",
    "            dcm_folder_path = os.path.join(TRAIN_IMG_DIR, study_folder_path, series_folder)\n",
    "            df = train_series_descriptions[train_series_descriptions[\"series_id\"] == int(series_folder)]\n",
    "            try:\n",
    "                series_desc = df[\"series_description\"].values[0][0]\n",
    "            except:\n",
    "                print(f\"Series description for series_id: {series_folder} not found! Skipping.\")\n",
    "                continue\n",
    "\n",
    "            plane = \"sagittal\" if series_desc != \"Axial T2\" else \"axial\"\n",
    "            dicom_data_3d = load_dicom_stack(dcm_folder_path, plane = plane)\n",
    "            \n",
    "            if dicom_data_3d[\"array\"].shape[0] == 0:\n",
    "                print(f\"Can't loop over size zero dicom data: {dicom_data_3d[\"array\"].shape}\")\n",
    "                continue\n",
    "            \n",
    "            for k in range(dicom_data_3d[\"array\"].shape[0]):\n",
    "                img = dicom_data_3d[\"array\"][k]\n",
    "                pixel_spacing = dicom_data_3d[\"pixel_spacing\"]\n",
    "                processed_img = preprocess_img(img, pixel_spacing)\n",
    "                save_folder = f\"train_png/{study_folder_path}/{series_folder}\"\n",
    "                filename = f\"{k+1}.png\"\n",
    "                save_img(processed_img, filename=filename, save_folder=save_folder)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"study_id\": \"first\", \"series_description\": \"first\", \"condition\": \"first\", \"level\": list, \"x\": list, \"y\": list}\n",
    "train_labels_grouped = train_labels.groupby([\"series_id\", \"instance_number\"], as_index=False).aggregate(d).reindex(columns=train_labels.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(img_file):\n",
    "    img_file = img_file.strip()\n",
    "    #Get img_file path, issue of a '/x' on the end.\n",
    "    if img_file[-1] == 'x':\n",
    "        img_file = img_file.removesuffix('/x')\n",
    "    return Image.open(img_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147218/147218 [00:41<00:00, 3572.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147218 33670 33569 79979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "IMG_PATHS = glob(os.path.join(\"train_png\", \"*/*/*png\"))\n",
    "\n",
    "ST1_IMG_PATHS, ST2_IMG_PATHS, AX_IMG_PATHS = [], [], []\n",
    "st1_train_df = train_series_descriptions[(train_series_descriptions[\"series_description\"] == \"Sagittal_T1\") | (train_series_descriptions[\"series_description\"] == \"Sagittal T1\")]\n",
    "st1_sids = st1_train_df[\"series_id\"].to_list()\n",
    "st2_train_df = train_series_descriptions[(train_series_descriptions[\"series_description\"] == \"Sagittal_T2_STIR\") | (train_series_descriptions[\"series_description\"] == \"Sagittal T2/STIR\")]\n",
    "st2_sids = st2_train_df[\"series_id\"].to_list()\n",
    "ax_train_df = train_series_descriptions[(train_series_descriptions[\"series_description\"] == \"Axial_T2\") | (train_series_descriptions[\"series_description\"] == \"Axial T2\")]\n",
    "ax_sids = ax_train_df[\"series_id\"].to_list()\n",
    "\n",
    "for path in tqdm(IMG_PATHS, maxinterval=len(IMG_PATHS)):\n",
    "    if any(str(sid) in path for sid in st1_sids):\n",
    "        ST1_IMG_PATHS.append(path)\n",
    "    elif any(str(sid) in path for sid in st2_sids):\n",
    "        ST2_IMG_PATHS.append(path)\n",
    "    elif any(str(sid) in path for sid in ax_sids):\n",
    "        AX_IMG_PATHS.append(path)\n",
    "\n",
    "print(len(IMG_PATHS), len(ST1_IMG_PATHS), len(ST2_IMG_PATHS), len(AX_IMG_PATHS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################################################\n",
    "############################################ SEGMENT IMAGES USING UNET ############################################################\n",
    "##########################################INSERT KAGGLE USERNAME AND LINK##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold  empty\n",
       "0.0   False    341\n",
       "      True     127\n",
       "1.0   False    297\n",
       "      True     132\n",
       "Name: id, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Using a UNet kaggle notebook, segment the discs.\"\"\"\n",
    "class CFG:\n",
    "    seed          = 101\n",
    "    debug         = False #Set debug = False for Full Training.\n",
    "    exp_name      = 'Baselinev2'\n",
    "    comment       = 'unet-efficientnet_b1-224x224-aug2-split2'\n",
    "    model_name    = 'Unet'\n",
    "    backbone      = 'efficientnet-b1'\n",
    "    train_bs      = 32          #Reduced on the mac from 128 due to memory failure of mps.\n",
    "    valid_bs      = train_bs    #Usually train_bs * 2, but changed due to memory failure.\n",
    "    img_size      = [224, 224]\n",
    "    epochs        = 25\n",
    "    lr            = 2e-3\n",
    "    scheduler     = 'CosineAnnealingLR'\n",
    "    min_lr        = 1e-6\n",
    "    T_max         = int(30000/train_bs*epochs)+50\n",
    "    T_0           = 25\n",
    "    warmup_epochs = 0\n",
    "    wd            = 1e-6\n",
    "    n_accumulate  = max(1, 32//train_bs)\n",
    "    n_fold        = 5\n",
    "    num_classes   = 3\n",
    "    device        = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\") #CHANGE ON KAGGLE FOR CUDA\n",
    "\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "def id2mask(id_):\n",
    "    idf = df[df['id']==id_]\n",
    "    wh = idf[['height','width']].iloc[0]\n",
    "    shape = (wh.height, wh.width, 3)\n",
    "    mask = np.zeros(shape, dtype=np.uint8)\n",
    "    for i, class_ in enumerate(['large_bowel', 'small_bowel', 'stomach']):\n",
    "        cdf = idf[idf['class']==class_]\n",
    "        rle = cdf.segmentation.squeeze()\n",
    "        if len(cdf) and not pd.isna(rle):\n",
    "            mask[..., i] = rle_decode(rle, shape[:2])\n",
    "    return mask\n",
    "\n",
    "def rgb2gray(mask):\n",
    "    pad_mask = np.pad(mask, pad_width=[(0,0),(0,0),(1,0)])\n",
    "    gray_mask = pad_mask.argmax(-1)\n",
    "    return gray_mask\n",
    "\n",
    "def gray2rgb(mask):\n",
    "    rgb_mask = tf.keras.utils.to_categorical(mask, num_classes=4)\n",
    "    return rgb_mask[..., 1:].astype(mask.dtype)\n",
    "\n",
    "def load_img(path):\n",
    "    if path[0] == '/':\n",
    "        path = path[1:]\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    img = np.tile(img[...,None], [1, 1, 3]) # gray to rgb\n",
    "    img = img.astype('float32') # original is uint16\n",
    "    mx = np.max(img)\n",
    "    if mx:\n",
    "        img/=mx # scale image to [0, 1]\n",
    "    return img\n",
    "\n",
    "def load_msk(path):\n",
    "    msk = np.load(path, allow_pickle=True)\n",
    "    msk = msk.astype('float32')\n",
    "    msk/=255.0\n",
    "    return msk\n",
    "    \n",
    "def show_img(img, mask=None):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "\n",
    "    plt.imshow(img, cmap='bone')\n",
    "    \n",
    "    if mask is not None:\n",
    "        plt.imshow(mask, alpha=0.5)\n",
    "        handles = [Rectangle((0,0),1,1, color=_c) for _c in [(0.667,0.0,0.0), (0.0,0.667,0.0), (0.0,0.0,0.667)]]\n",
    "\n",
    "    plt.axis('off')\n",
    "\n",
    "def rle_decode(mask_rle, shape):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)  # Needed to align to RLE direction\n",
    "# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "skf = StratifiedGroupKFold(n_splits=2, shuffle=True, random_state=CFG.seed)\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['empty'], groups = df[\"case\"])):\n",
    "    df.loc[val_idx, 'fold'] = fold\n",
    "display(df.groupby(['fold','empty'])['id'].count())\n",
    "\n",
    "class BuildDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, label=True, transforms=None):\n",
    "        self.df         = df\n",
    "        self.label      = label\n",
    "        self.img_paths  = df['image_slices (png)'].tolist()\n",
    "        self.msk_paths  = df['mask_slices (png)'].tolist()\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path  = self.img_paths[index]\n",
    "        img = []\n",
    "        img = load_img(img_path)\n",
    "        \n",
    "        if self.label:\n",
    "            msk_path = self.msk_paths[index]\n",
    "            msk = load_img(msk_path)\n",
    "            if self.transforms:\n",
    "                data = self.transforms(image=img, mask=msk)\n",
    "                img  = data['image']\n",
    "                msk  = data['mask']\n",
    "            img = np.transpose(img, (2, 0, 1))\n",
    "            msk = np.transpose(msk, (2, 0, 1))\n",
    "            return torch.tensor(img), torch.tensor(msk)\n",
    "        else:\n",
    "            if self.transforms:\n",
    "                data = self.transforms(image=img)\n",
    "                img  = data['image']\n",
    "            img = np.transpose(img, (2, 0, 1))\n",
    "            return torch.tensor(img)\n",
    "\n",
    "data_transforms = {\n",
    "    \"train\": A.Compose([\n",
    "        A.Resize(*CFG.img_size, interpolation=cv2.INTER_NEAREST),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "#         A.VerticalFlip(p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.05, rotate_limit=10, p=0.5),\n",
    "        A.OneOf([\n",
    "            A.GridDistortion(num_steps=5, distort_limit=0.05, p=1.0),\n",
    "# #             A.OpticalDistortion(distort_limit=0.05, shift_limit=0.05, p=1.0),\n",
    "            A.ElasticTransform(alpha=1, sigma=50, alpha_affine=None, p=1.0)\n",
    "        ], p=0.25),\n",
    "        A.CoarseDropout(max_holes=8, max_height=CFG.img_size[0]//20, max_width=CFG.img_size[1]//20,\n",
    "                         min_holes=5, fill_value=0, mask_fill_value=0, p=0.5),\n",
    "        ], p=1.0),\n",
    "    \n",
    "    \"valid\": A.Compose([\n",
    "        A.Resize(*CFG.img_size, interpolation=cv2.INTER_NEAREST),\n",
    "        ], p=1.0)\n",
    "}\n",
    "\n",
    "def prepare_loaders(fold, debug=False):\n",
    "    train_df = df.query(\"fold!=@fold\").reset_index(drop=True)\n",
    "    valid_df = df.query(\"fold==@fold\").reset_index(drop=True)\n",
    "    if debug:\n",
    "        train_df = train_df.head(32*5).query(\"empty==0\")\n",
    "        valid_df = valid_df.head(32*3).query(\"empty==0\")\n",
    "    train_dataset = BuildDataset(train_df, transforms=data_transforms['train'])\n",
    "    valid_dataset = BuildDataset(valid_df, transforms=data_transforms['valid'])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CFG.train_bs if not debug else 20, \n",
    "                              num_workers=0, shuffle=True, pin_memory=True, drop_last=False)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CFG.valid_bs if not debug else 20, \n",
    "                              num_workers=0, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    return train_loader, valid_loader\n",
    "\n",
    "train_loader, valid_loader= prepare_loaders(fold=0, debug=True)\n",
    "imgs, msks = next(iter(train_loader))\n",
    "imgs.size(), msks.size()\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "def build_model():\n",
    "    model = smp.Unet(\n",
    "        encoder_name=CFG.backbone,      # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "        encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "        in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "        classes=CFG.num_classes,        # model output channels (number of classes in your dataset)\n",
    "        activation=None,\n",
    "    )\n",
    "    #model.encoder.load_state_dict(torch.load('/kaggle/input/efficientnet-b1-1c1461ff.pth'))\n",
    "    model.to(CFG.device)\n",
    "    return model\n",
    "\n",
    "def load_model(path):\n",
    "    model = build_model()\n",
    "    model.load_state_dict(torch.load(\"best_epoch-00.bin\"))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "JaccardLoss = smp.losses.JaccardLoss(mode='multilabel')\n",
    "DiceLoss    = smp.losses.DiceLoss(mode='multilabel')\n",
    "BCELoss     = smp.losses.SoftBCEWithLogitsLoss()\n",
    "LovaszLoss  = smp.losses.LovaszLoss(mode='multilabel', per_image=False)\n",
    "TverskyLoss = smp.losses.TverskyLoss(mode='multilabel', log_loss=False)\n",
    "\n",
    "def dice_coef(y_true, y_pred, thr=0.5, dim=(2,3), epsilon=0.001):\n",
    "    y_true = y_true.to(torch.float32)\n",
    "    y_pred = (y_pred>thr).to(torch.float32)\n",
    "    inter = (y_true*y_pred).sum(dim=dim)\n",
    "    den = y_true.sum(dim=dim) + y_pred.sum(dim=dim)\n",
    "    dice = ((2*inter+epsilon)/(den+epsilon)).mean(dim=(1,0))\n",
    "    return dice\n",
    "\n",
    "def iou_coef(y_true, y_pred, thr=0.5, dim=(2,3), epsilon=0.001):\n",
    "    y_true = y_true.to(torch.float32)\n",
    "    y_pred = (y_pred>thr).to(torch.float32)\n",
    "    inter = (y_true*y_pred).sum(dim=dim)\n",
    "    union = (y_true + y_pred - y_true*y_pred).sum(dim=dim)\n",
    "    iou = ((inter+epsilon)/(union+epsilon)).mean(dim=(1,0))\n",
    "    return iou\n",
    "\n",
    "def criterion(y_pred, y_true):\n",
    "    return 0.5*BCELoss(y_pred, y_true) + 0.5*TverskyLoss(y_pred, y_true)\n",
    "\n",
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    model.train()\n",
    "    scaler = amp.GradScaler()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Train ')\n",
    "    for step, (images, masks) in pbar:         \n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        masks  = masks.to(device, dtype=torch.float)\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        with amp.autocast(enabled=True):\n",
    "            y_pred = model(images)\n",
    "            loss   = criterion(y_pred, masks)\n",
    "            loss   = loss / CFG.n_accumulate\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "    \n",
    "        if (step + 1) % CFG.n_accumulate == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "                \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        \n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix(train_loss=f'{epoch_loss:0.4f}',\n",
    "                        lr=f'{current_lr:0.5f}',\n",
    "                        gpu_mem=f'{mem:0.2f} GB')\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    val_scores = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Valid ')\n",
    "    for step, (images, masks) in pbar:        \n",
    "        images  = images.to(device, dtype=torch.float)\n",
    "        masks   = masks.to(device, dtype=torch.float)\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        y_pred  = model(images)\n",
    "        loss    = criterion(y_pred, masks)\n",
    "        \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        \n",
    "        y_pred = nn.Sigmoid()(y_pred)\n",
    "        val_dice = dice_coef(masks, y_pred).cpu().detach().numpy()\n",
    "        val_jaccard = iou_coef(masks, y_pred).cpu().detach().numpy()\n",
    "        val_scores.append([val_dice, val_jaccard])\n",
    "        \n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix(valid_loss=f'{epoch_loss:0.4f}',\n",
    "                        lr=f'{current_lr:0.5f}',\n",
    "                        gpu_memory=f'{mem:0.2f} GB')\n",
    "    val_scores  = np.mean(val_scores, axis=0)\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss, val_scores\n",
    "\n",
    "def run_training(model, optimizer, scheduler, device, num_epochs):    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"cuda: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "    \n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_dice      = -np.inf\n",
    "    best_epoch     = -1\n",
    "    history = defaultdict(list)\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        gc.collect()\n",
    "        print(f'Epoch {epoch}/{num_epochs}', end='')\n",
    "        train_loss = train_one_epoch(model, optimizer, scheduler, \n",
    "                                           dataloader=train_loader, \n",
    "                                           device=CFG.device, epoch=epoch)\n",
    "        \n",
    "        val_loss, val_scores = valid_one_epoch(model, valid_loader, \n",
    "                                                 device=CFG.device, \n",
    "                                                 epoch=epoch)\n",
    "        val_dice, val_jaccard = val_scores\n",
    "    \n",
    "        history['Train Loss'].append(train_loss)\n",
    "        history['Valid Loss'].append(val_loss)\n",
    "        history['Valid Dice'].append(val_dice)\n",
    "        history['Valid Jaccard'].append(val_jaccard)\n",
    "        \n",
    "        # Log the metrics\n",
    "        metrics = {\"Train Loss\": train_loss, \n",
    "                    \"Valid Loss\": val_loss,\n",
    "                    \"Valid Dice\": val_dice,\n",
    "                    \"Valid Jaccard\": val_jaccard,\n",
    "                    \"LR\":scheduler.get_last_lr()[0]}\n",
    "        \n",
    "        print(f'Valid Dice: {val_dice:0.4f} | Valid Jaccard: {val_jaccard:0.4f}')\n",
    "\n",
    "        if val_dice >= best_dice:\n",
    "            print(f\"{c_}Valid Score Improved ({best_dice:0.4f} ---> {val_dice:0.4f})\")\n",
    "            best_dice    = val_dice\n",
    "            best_jaccard = val_jaccard\n",
    "            best_epoch   = epoch\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = f\"best_epoch-{fold:02d}.bin\"\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            print(f\"Model Saved{sr_}\")\n",
    "\n",
    "        last_model_wts = copy.deepcopy(model.state_dict())\n",
    "        PATH = f\"last_epoch-{fold:02d}.bin\"\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "                \n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history\n",
    "\n",
    "def fetch_scheduler(optimizer):\n",
    "    if CFG.scheduler == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CFG.T_max, \n",
    "                                                   eta_min=CFG.min_lr)\n",
    "    elif CFG.scheduler == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CFG.T_0, \n",
    "                                                             eta_min=CFG.min_lr)\n",
    "    elif CFG.scheduler == 'ReduceLROnPlateau':\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                   mode='min',\n",
    "                                                   factor=0.1,\n",
    "                                                   patience=7,\n",
    "                                                   threshold=0.0001,\n",
    "                                                   min_lr=CFG.min_lr,)\n",
    "    elif CFG.scheduer == 'ExponentialLR':\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.85)\n",
    "    elif CFG.scheduler == None:\n",
    "        return None\n",
    "        \n",
    "    return scheduler\n",
    "\n",
    "if not os.path.exists(\"last_epoch-00.bin\"):\n",
    "    model = build_model()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
    "    scheduler = fetch_scheduler(optimizer)\n",
    "    for fold in range(1):\n",
    "        print(f'#' * 15)\n",
    "        print(f'### Fold: {fold}')\n",
    "        print(f'#' * 15)\n",
    "\n",
    "        # Prepare loaders and model\n",
    "        train_loader, valid_loader = prepare_loaders(fold=fold, debug=CFG.debug)\n",
    "        model = build_model()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
    "        scheduler = fetch_scheduler(optimizer)\n",
    "\n",
    "        # Print basic info instead of wandb logging\n",
    "        print(f\"Starting training for fold-{fold} with model {CFG.model_name} and dimensions {CFG.img_size[0]}x{CFG.img_size[1]}\")\n",
    "\n",
    "        # Training loop\n",
    "        model, history = run_training(model, optimizer, scheduler,\n",
    "                                    device=CFG.device,\n",
    "                                    num_epochs=CFG.epochs)\n",
    "\n",
    "        # Optionally, print completion message\n",
    "        print(f\"Completed fold-{fold}\")\n",
    "\n",
    "def plot_batch(imgs, msks, size=3):\n",
    "    plt.figure(figsize=(5*5, 5))\n",
    "    for idx in range(size):\n",
    "        plt.subplot(1, 5, idx+1)\n",
    "        img = imgs[idx,].permute((1, 2, 0)).numpy()*255.0\n",
    "        img = img.astype('uint8')\n",
    "        msk = msks[idx,].permute((1, 2, 0)).numpy()*255.0\n",
    "        show_img(img, msk)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    device = torch.device(\"mps\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33569\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.image\n",
    "from lumbar_dataset import *\n",
    "\n",
    "model = load_model(f\"best_epoch-00.bin\").to(device)\n",
    "model.eval()\n",
    "\n",
    "st2_predict_dataset = RSNATrainPredict(ST2_IMG_PATHS)\n",
    "print(len(st2_predict_dataset))\n",
    "segmentation_dataloader = DataLoader(st2_predict_dataset, batch_size=64,\n",
    "                          num_workers=8, shuffle=False, pin_memory=True)\n",
    "\n",
    "def save_prediction(img_path, pred):\n",
    "    filename = img_path.replace('train_png', 'nnUNet_segments').replace('png', 'npy')\n",
    "    folder_path = \"/\".join(filename.split('/')[:-1])\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    gray_mask = pred[:, :, 0]\n",
    "    np.save(filename, gray_mask)\n",
    "\n",
    "def process_and_save(data):\n",
    "    img, img_paths = data[\"img\"].to(device), data[\"img_path\"]\n",
    "    with torch.no_grad():\n",
    "        pred = model(img)\n",
    "        pred = (nn.Sigmoid()(pred) > 0.5).float()\n",
    "    pred = pred.detach().cpu().numpy()\n",
    "    pred = np.transpose(pred, (0, 2, 3, 1)) \n",
    "    for k in range(pred.shape[0]): #Batch_size.\n",
    "        current_pred, current_instance = pred[k], img_paths[k].split('/')[-1].split('.')[0]\n",
    "        if int(current_instance) <= 3 and np.count_nonzero(current_pred == 1.) > 50: #Need to mess around with it to find the best miniumum number of pixels.\n",
    "            save_prediction(img_paths[k], current_pred) \n",
    "        elif int(current_instance) <= 3 and np.count_nonzero(current_pred == 1.) > 50: #Again, do testing.\n",
    "            save_prediction(img_paths[k], current_pred) \n",
    "        elif np.count_nonzero(current_pred == 1.) > 50:\n",
    "            save_prediction(img_paths[k], current_pred) \n",
    "\n",
    "if not os.path.exists(\"nnUNet_segments\"):\n",
    "    for data in tqdm(segmentation_dataloader, total=int(len(st2_predict_dataset) / 64)):\n",
    "        process_and_save(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33670\n",
      "36728\n"
     ]
    }
   ],
   "source": [
    "st1_predict_dataset = RSNATrainPredict(ST1_IMG_PATHS)\n",
    "print(len(st1_predict_dataset))\n",
    "segmentation_dataloader = DataLoader(st1_predict_dataset, batch_size=64,\n",
    "                          num_workers=8, shuffle=False, pin_memory=True)\n",
    "\n",
    "if not os.path.exists(\"nnUNet_segments\"):\n",
    "    for data in tqdm(segmentation_dataloader, total=int(len(st1_predict_dataset) / 64)):\n",
    "        process_and_save(data)\n",
    "\n",
    "print(len(glob(os.path.join(\"nnUNet_segments\", \"*/*/*npy\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################################################################\n",
    "############################################# SEGMENT SPINAL CANAL WITH SAM2 ####################################################\n",
    "#################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Now using Meta\\'s SAM2 model, obtain the spinal canal or degeneracies in the imgs.\\nfrom process_imgs import *\\nfrom multiprocessing import Pool\\n\\npredictor = SAM2ImagePredictor.from_pretrained(\"facebook/sam2-hiera-large\", device=\"cpu\")\\n\\n#CREATE A FOLDER OF SUITABLE SEGEMENTATIONS OF \\n\\ndf = train_labels.copy()\\ndf = df.set_index([\"study_id\", \"series_id\", \"instance_number\"])[[\"x\", \"y\", \"condition\"]]\\ndf = df.drop([df[\"condition\"].str.contains(\"subarticular\")].index) \\ndf = df.drop([df[\"condition\"].str.contains(\"foraminal\")].index) \\n\\no = 0\\nfor (study_id, series_id, instance_number), chunk in tqdm(df.groupby(level=[0, 1, 2])[[\"x\", \"y\"]]):\\n    process_image(study_id, series_id, instance_number, chunk)\\n    o+=1\\n    if o == 2: break\\n\\nif not os.path.exists(\"nnUNet_spinal_canal\"):\\n    with Pool(processes=10) as pool:\\n        args = [(study_id, series_id, instance_number, chunk) for (study_id, series_id, instance_number), chunk in df.groupby(level=[0, 1, 2])[[\"x\", \"y\"]]]\\n        tqdm(pool.starmap(process_image, args), maxinterval = len(df.groupby(level=[0, 1, 2])[[\"x\", \"y\"]]))'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Now using Meta's SAM2 model, obtain the spinal canal or degeneracies in the imgs.\n",
    "from process_imgs import *\n",
    "from multiprocessing import Pool\n",
    "\n",
    "predictor = SAM2ImagePredictor.from_pretrained(\"facebook/sam2-hiera-large\", device=\"cpu\")\n",
    "\n",
    "#CREATE A FOLDER OF SUITABLE SEGEMENTATIONS OF \n",
    "\n",
    "df = train_labels.copy()\n",
    "df = df.set_index([\"study_id\", \"series_id\", \"instance_number\"])[[\"x\", \"y\", \"condition\"]]\n",
    "df = df.drop([df[\"condition\"].str.contains(\"subarticular\")].index) \n",
    "df = df.drop([df[\"condition\"].str.contains(\"foraminal\")].index) \n",
    "\n",
    "o = 0\n",
    "for (study_id, series_id, instance_number), chunk in tqdm(df.groupby(level=[0, 1, 2])[[\"x\", \"y\"]]):\n",
    "    process_image(study_id, series_id, instance_number, chunk)\n",
    "    o+=1\n",
    "    if o == 2: break\n",
    "\n",
    "if not os.path.exists(\"nnUNet_spinal_canal\"):\n",
    "    with Pool(processes=10) as pool:\n",
    "        args = [(study_id, series_id, instance_number, chunk) for (study_id, series_id, instance_number), chunk in df.groupby(level=[0, 1, 2])[[\"x\", \"y\"]]]\n",
    "        tqdm(pool.starmap(process_image, args), maxinterval = len(df.groupby(level=[0, 1, 2])[[\"x\", \"y\"]]))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes in the segmentation mask.\n",
    "0: Background/unimportant\n",
    "1: Spinal canal\n",
    "2: L1_L2 disc\n",
    "...\n",
    "6: L5_S1 disc\n",
    "7: Normal/mild degeneration\n",
    "8: Moderate degeneration\n",
    "9: Severe degeneration\n",
    "10: Other Discs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################################################\n",
    "################################################### NNUNET SETUP ##################################################################\n",
    "###################################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######################################################################\n",
    "Please cite the following paper when using nnU-Net:\n",
    "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nnUNet_raw/\n",
    "├── Dataset_LumbarDegeneration\n",
    "    ├── dataset.json  #Containing the metadata of the dataset.\n",
    "    ├── imagesTr\n",
    "        │   ├── 702807833_1_0000.png  #seriesID_instanceNumber_000(0,1,2).png.\n",
    "        │   ├── 1054713880_1_0001.png  #0000: Sagittal T1, 0001: Sagittal T2/STIR, 0002: Axial T2\n",
    "        │   ├── 2448190387_1_0002.png\n",
    "    ├── imagesTs  #Test images (optional).\n",
    "    └── labelsTr\n",
    "        ├── 702807833_1.png\n",
    "        ├── 1054713880_1.png\n",
    "        ├── ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNET_ST1_DIR = \"nnUNet_raw/Dataset001_ST1_Degeneration\"\n",
    "UNET_ST2_DIR = \"nnUNet_raw/Dataset002_ST2_Degeneration\"\n",
    "os.makedirs(os.path.join(UNET_ST1_DIR, \"imagesTr\"), exist_ok = True)\n",
    "os.makedirs(os.path.join(UNET_ST1_DIR, \"imagesTs\"), exist_ok = True)\n",
    "os.makedirs(os.path.join(UNET_ST1_DIR, \"labelsTr\"), exist_ok = True)\n",
    "\n",
    "os.makedirs(os.path.join(UNET_ST2_DIR, \"imagesTr\"), exist_ok = True)\n",
    "os.makedirs(os.path.join(UNET_ST2_DIR, \"imagesTs\"), exist_ok = True)\n",
    "os.makedirs(os.path.join(UNET_ST2_DIR, \"labelsTr\"), exist_ok = True)\n",
    "\n",
    "os.makedirs(\"nnUNet_preprocessed\", exist_ok = True)\n",
    "os.makedirs(\"nnUNet_results\", exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create dataset.json\"\"\"\n",
    "import json\n",
    "s1,s2 = \"sagittal_t1\", \"sagittal_t2\"\n",
    "lf,rf,scs = \"left_neural_foraminal_narrowing\", \"right_neural_foraminal_narrowing\", \"spinal_canal_stenosis\"\n",
    "l1,l2,l3,l4,l5 = \"l1_l2\", \"l2_l3\", \"l3_l4\", \"l4_l5\", \"l5_s1\"\n",
    "n,m,s,i = \"normal_mild\", \"moderate\", \"severe\", \"intact\"\n",
    "\n",
    "st1_classes = {\n",
    "        \"background\": 0,\n",
    "        \"other_disc\": 1,\n",
    "\n",
    "        f\"{lf}_{l1}_{n}\": 2, #Sagittal T1: left_neural_foraminal_narrowing n/m/s.\n",
    "        f\"{lf}_{l2}_{n}\": 3,\n",
    "        f\"{lf}_{l3}_{n}\": 4,\n",
    "        f\"{lf}_{l4}_{n}\": 5,\n",
    "        f\"{lf}_{l5}_{n}\": 6,\n",
    "        f\"{lf}_{l1}_{m}\": 7,\n",
    "        f\"{lf}_{l2}_{m}\": 8,\n",
    "        f\"{lf}_{l3}_{m}\": 9,\n",
    "        f\"{lf}_{l4}_{m}\": 10,\n",
    "        f\"{lf}_{l5}_{m}\": 11,\n",
    "        f\"{lf}_{l1}_{s}\": 12,\n",
    "        f\"{lf}_{l2}_{s}\": 13,\n",
    "        f\"{lf}_{l3}_{s}\": 14,\n",
    "        f\"{lf}_{l4}_{s}\": 15,\n",
    "        f\"{lf}_{l5}_{s}\": 16,\n",
    "\n",
    "        f\"{rf}_{l1}_{n}\": 17, #Sagittal T1: right_neural_foraminal_narrowing n/m/s.\n",
    "        f\"{rf}_{l2}_{n}\": 18,\n",
    "        f\"{rf}_{l3}_{n}\": 19,\n",
    "        f\"{rf}_{l4}_{n}\": 20,\n",
    "        f\"{rf}_{l5}_{n}\": 21,\n",
    "        f\"{rf}_{l1}_{m}\": 22,\n",
    "        f\"{rf}_{l2}_{m}\": 23,\n",
    "        f\"{rf}_{l3}_{m}\": 24,\n",
    "        f\"{rf}_{l4}_{m}\": 25,\n",
    "        f\"{rf}_{l5}_{m}\": 26,\n",
    "        f\"{rf}_{l1}_{s}\": 27,\n",
    "        f\"{rf}_{l2}_{s}\": 28,\n",
    "        f\"{rf}_{l3}_{s}\": 29,\n",
    "        f\"{rf}_{l4}_{s}\": 30,\n",
    "        f\"{rf}_{l5}_{s}\": 31,\n",
    "\n",
    "        f\"{s1}_l1\": 32, #Sagittal T1 disc.\n",
    "        f\"{s1}_l2\": 33,\n",
    "        f\"{s1}_l3\": 34,\n",
    "        f\"{s1}_l4\": 35,\n",
    "        f\"{s1}_l5\": 36,\n",
    "        f\"{s1}_s1\": 37,\n",
    "    }\n",
    "\n",
    "st2_classes = {\n",
    "        \"background\": 0,\n",
    "        \"other_disc\": 1,\n",
    "\n",
    "        f\"{scs}_{l1}_{n}\": 2, #Sagittal T2/STIR spinal_canal_stenosis n/m/s.\n",
    "        f\"{scs}_{l2}_{n}\": 3,\n",
    "        f\"{scs}_{l3}_{n}\": 4,\n",
    "        f\"{scs}_{l4}_{n}\": 5,\n",
    "        f\"{scs}_{l5}_{n}\": 6,\n",
    "        f\"{scs}_{l1}_{m}\": 7,\n",
    "        f\"{scs}_{l2}_{m}\": 8,\n",
    "        f\"{scs}_{l3}_{m}\": 9,\n",
    "        f\"{scs}_{l4}_{m}\": 10,\n",
    "        f\"{scs}_{l5}_{m}\": 11,\n",
    "        f\"{scs}_{l1}_{s}\": 12,\n",
    "        f\"{scs}_{l2}_{s}\": 13,\n",
    "        f\"{scs}_{l3}_{s}\": 14,\n",
    "        f\"{scs}_{l4}_{s}\": 15,\n",
    "        f\"{scs}_{l5}_{s}\": 16, \n",
    "\n",
    "        f\"{s2}_l1\": 17, #Sagittal T2/STIR disc.\n",
    "        f\"{s2}_l2\": 18,\n",
    "        f\"{s2}_l3\": 19,\n",
    "        f\"{s2}_l4\": 20,\n",
    "        f\"{s2}_l5\": 21,\n",
    "        f\"{s2}_s1\": 22,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48692\n",
      "48692 61899\n",
      "110591\n",
      "61941\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Add 'inferenced' degenerative rows to the train_labels dataframe.\"\"\"\n",
    "def inference_rows(rows, instance):\n",
    "    rows = rows.drop_duplicates(subset = [\"level\"])\n",
    "    rows[\"instance_number\"] = instance\n",
    "    return rows\n",
    "\n",
    "erows = pd.DataFrame(columns = train_labels.columns)\n",
    "sagittal_idf = train_labels[(train_labels[\"condition\"] != \"left_subarticular_stenosis\") | (train_labels[\"condition\"] != \"right_subarticular_stenosis\")]\n",
    "print(len(sagittal_idf))\n",
    "\n",
    "for idx, chunk in sagittal_idf.groupby(\"series_id\"):\n",
    "    chunk = chunk.reset_index()\n",
    "    if len(chunk) < 2:\n",
    "        continue #Skip any with 1 row in as no data\n",
    "\n",
    "    for instance in np.unique(chunk[\"instance_number\"].to_numpy()):\n",
    "        valid_ins = [instance - 1, instance, instance + 1]\n",
    "        valid_cond = chunk[chunk[\"instance_number\"] == instance][\"condition\"].values[0]\n",
    "        valid_rows = chunk[(chunk[\"instance_number\"].isin(valid_ins)) & (chunk[\"condition\"] == valid_cond)]\n",
    "        irows = inference_rows(valid_rows, instance)\n",
    "        erows = pd.concat([erows, irows], ignore_index = True)\n",
    "\n",
    "print(len(sagittal_idf), len(erows))\n",
    "itrain_labels = pd.concat([sagittal_idf, erows], ignore_index = True)\n",
    "print(len(itrain_labels))\n",
    "itrain_labels = itrain_labels.drop_duplicates(subset=['series_id', 'instance_number', 'level'])\n",
    "itrain_labels = itrain_labels[train_labels.columns]\n",
    "print(len(itrain_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      study_id   series_id series_description instance_number  \\\n",
      "15243  4003253  1054713880        Sagittal_T1              11   \n",
      "15244  4003253  1054713880        Sagittal_T1              11   \n",
      "15245  4003253  1054713880        Sagittal_T1              11   \n",
      "15246  4003253  1054713880        Sagittal_T1              11   \n",
      "15247  4003253  1054713880        Sagittal_T1              11   \n",
      "\n",
      "                             condition  level           x           y  \n",
      "15243  left_neural_foraminal_narrowing  l1_l2  114.374558   73.512367  \n",
      "15244  left_neural_foraminal_narrowing  l4_l5  108.794275  146.762075  \n",
      "15245  left_neural_foraminal_narrowing  l5_s1  114.975332  168.850095  \n",
      "15246  left_neural_foraminal_narrowing  l2_l3  111.604240   99.236749  \n",
      "15247  left_neural_foraminal_narrowing  l3_l4  109.595707  126.726297  \n"
     ]
    }
   ],
   "source": [
    "itrain_labels = itrain_labels.sort_values(['series_id', 'instance_number']).reset_index()\n",
    "itrain_labels = itrain_labels[train_labels.columns]\n",
    "print(itrain_labels[(itrain_labels[\"series_id\"] == 1054713880) & (itrain_labels[\"instance_number\"] == 11)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unqiue elements: ['Sagittal_T1' 'Sagittal_T2_STIR']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Create appropriate dataframe containing the severity of the coordinate for the classification of each disc in each image\"\"\"\n",
    "class_df = pd.merge(itrain_labels, train_series_descriptions, on = [\"study_id\", \"series_id\"])\n",
    "class_df = class_df[class_df[\"series_description_x\"] != \"Axial_T2\"].drop(\"series_description_y\", axis = 1).rename(columns={\"series_description_x\": \"series_description\"})\n",
    "class_df = class_df.dropna()\n",
    "\n",
    "def rename_cell(col, val):\n",
    "    return f\"{col}_{val.lower().replace('/', '_')}\"\n",
    "\n",
    "def get_class(row):\n",
    "    col_name = f\"{row['condition']}_{row['level']}\"  \n",
    "    #print(col_name)\n",
    "    if col_name in row.index: \n",
    "        return row[col_name]\n",
    "    else:\n",
    "        print(f\"No column with name: {col_name}\\n{row}\"); return None\n",
    "\n",
    "def class_to_number(cell, classes):\n",
    "    return classes[cell] if classes[cell] is not None else np.nan\n",
    "\n",
    "def process_nnunet_df(class_df, classes, st1_st2):\n",
    "    train_copy = train[train.columns[:16]] #Drop subarticular columns. (Axial T2).\n",
    "    n = 1 if st1_st2 == \"st2\" else 6\n",
    "    m = 6 if st1_st2 == \"st2\" else 16\n",
    "    cols = [train.columns[0]] + list(train.columns[n:m])\n",
    "    train_copy = train[cols] #Drop correct condition columns, depending on sagt1 or t2. Including the study_id column.\n",
    "    for col in train_copy.columns[1:]:\n",
    "        train_copy[col] = train_copy[col].apply(lambda x: rename_cell(col, x))\n",
    "\n",
    "    class_df = pd.merge(class_df, train_copy, on = \"study_id\")\n",
    "    class_df['class_number'] = class_df.apply(get_class, axis=1)\n",
    "    class_df = class_df.drop(class_df.columns[8:-1], axis = 1)\n",
    "    class_df[\"class_number\"] = class_df[\"class_number\"].apply(lambda x: class_to_number(x, classes))\n",
    "    if len(class_df.dropna()) != len(class_df): print(\"nans in the dataframe\") \n",
    "    return class_df\n",
    "\n",
    "class_df = class_df.drop(\n",
    "    class_df[\n",
    "        (class_df[\"series_description\"] == \"Sagittal_T1\") & \n",
    "        (class_df[\"condition\"].str.contains('canal'))\n",
    "    ].index\n",
    ")\n",
    "\n",
    "class_df = class_df.drop(\n",
    "    class_df[\n",
    "        (class_df[\"series_description\"] == \"Sagittal_T2_STIR\") & \n",
    "        (class_df[\"condition\"].str.contains('narrowing'))\n",
    "    ].index\n",
    ")\n",
    "\n",
    "st1_class_df = process_nnunet_df(class_df[class_df[\"series_description\"] == \"Sagittal_T1\"], st1_classes, \"st1\")\n",
    "st1_class_df = st1_class_df.dropna()\n",
    "print(\"unqiue elements:\", np.unique(class_df[\"series_description\"].to_numpy()))\n",
    "st2_class_df = process_nnunet_df(class_df[class_df[\"series_description\"] == \"Sagittal_T2_STIR\"], st2_classes, \"st2\")\n",
    "st2_class_df = st2_class_df.dropna()\n",
    "\n",
    "if np.unique(st1_class_df[\"class_number\"].to_numpy()).shape[0] != 30:\n",
    "    print(\"Error in st1_class_df\") \n",
    "if np.unique(st2_class_df[\"class_number\"].to_numpy()).shape[0] != 15:\n",
    "    print(\"Error in st2_class_df\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import label\n",
    "from skimage.measure import regionprops\n",
    "\n",
    "\n",
    "\"\"\"Label the masks with the vertebrae class as well as the disc class. (From either st1_classes or st2_classes)\"\"\"\n",
    "\"\"\"General Process: -> Take the highest disc from the dataframe (l1_l2)\n",
    "-> Find the center and sides of the vertebrae\n",
    "-> Fill a rectangle below the disc, not overlapping the vertebrae below, representing the disc between the two vertebrae\n",
    "-> Append to an array when completed\n",
    "-> Repeat until l5_s1 is reached\n",
    "-> Label s1\n",
    "-> Compare the array of completed discs/vertebrae to the list of all discs\n",
    "-> Move up to staring vertebrae, until all discs/vertebrae are completed\n",
    "-> Label the remaining vertebrae as \"other_disc\": 2 #The name for these is wrong, however is it unimportant for now.\n",
    "\"\"\"\n",
    "\n",
    "def auto_label_mask(mask):\n",
    "    labeled_mask, num_features = label(mask) \n",
    "    return labeled_mask\n",
    "    \n",
    "def correct_labels_for_overlap(mask, classes):\n",
    "    #First change the auto-assigned background color(s) to 0.\n",
    "    unique, counts = np.unique(mask, return_counts=True)\n",
    "    sorted_indices = np.argsort(counts)[::-1] #Sort in descending order\n",
    "    class_values = classes.values()\n",
    "    for u in unique:\n",
    "        if u == 0:\n",
    "            continue\n",
    "        if u in class_values:\n",
    "            mask[mask == u] = u + 70 #70 ensures the overlapping pixel value is now completely unique.\n",
    "    return mask\n",
    "\n",
    "def auto_label_and_correct_mask(mask, classes):\n",
    "    color_mask = auto_label_mask(mask)\n",
    "    corrected_color_mask = correct_labels_for_overlap(color_mask, classes)\n",
    "    return corrected_color_mask\n",
    "\n",
    "def disc_to_vert_and_class(highest_disc, condition):\n",
    "    n = 15 if condition == \"spinal_canal_stenosis\" else 0\n",
    "    if highest_disc == \"l1_l2\": return \"l1\", (32 - n)\n",
    "    elif highest_disc == \"l2_l3\": return \"l2\", (33 - n)\n",
    "    elif highest_disc == \"l3_l4\": return \"l3\", (34 - n)\n",
    "    elif highest_disc == \"l4_l5\": return \"l4\", (35 - n)\n",
    "    elif highest_disc == \"l5_s1\": return \"l5\", (36 - n)\n",
    "\n",
    "\n",
    "def align_verts_to_val(highest_vert, vert_val):\n",
    "    if highest_vert == \"l1\": \n",
    "        return {\"l1\": vert_val + 0, \"l2\": vert_val + 1, \"l3\": vert_val + 2, \"l4\": vert_val + 3, \"l5\": vert_val + 4, \"s1\": vert_val + 5}\n",
    "    elif highest_vert == \"l2\": \n",
    "        return {\"l1\": vert_val - 1, \"l2\": vert_val + 0, \"l3\": vert_val + 1, \"l4\": vert_val + 2, \"l5\": vert_val + 3, \"s1\": vert_val + 4}\n",
    "    elif highest_vert == \"l3\": \n",
    "        return {\"l1\": vert_val - 2, \"l2\": vert_val - 1, \"l3\": vert_val + 0, \"l4\": vert_val + 1, \"l5\": vert_val + 2, \"s1\": vert_val + 3}\n",
    "    elif highest_vert == \"l4\": \n",
    "        return {\"l1\": vert_val - 3, \"l2\": vert_val - 2, \"l3\": vert_val - 1, \"l4\": vert_val + 0, \"l5\": vert_val + 1, \"s1\": vert_val + 2}\n",
    "    elif highest_vert == \"l5\": \n",
    "        return {\"l1\": vert_val - 4, \"l2\": vert_val - 3, \"l3\": vert_val - 2, \"l4\": vert_val - 1, \"l5\": vert_val + 0, \"s1\": vert_val + 1} \n",
    "    else:\n",
    "        print(f\"Vertebrae {highest_vert} invalid!\")\n",
    "    #There is no \"s1\" condition.\n",
    "        \n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def find_vert_with_coords(mask, x, y):\n",
    "    central_x_est, central_y_est = int(x) - 11, int(y) - 8\n",
    "    vert_val = mask[central_y_est, central_x_est]\n",
    "    if vert_val == 0:\n",
    "        offsets = [(dx, dy) for dx in range(-3, 4) for dy in range(-3, 4)]\n",
    "        for dx, dy in offsets:\n",
    "            temp_x_est, temp_y_est = central_x_est + dx, central_y_est + dy\n",
    "            \n",
    "            if 0 <= temp_y_est < mask.shape[0] and 0 <= temp_x_est < mask.shape[1]:\n",
    "                vert_val = mask[temp_y_est, temp_x_est]\n",
    "                if vert_val != 0:\n",
    "                    return vert_val\n",
    "    \n",
    "        '''#Debugging code.\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(mask, cmap='gray')\n",
    "        rect = patches.Rectangle((central_x_est - 3, central_y_est - 3), 7, 7, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)'''\n",
    "        return None\n",
    "    else:\n",
    "        return vert_val\n",
    "\n",
    "def locate_vertebrae(mask, highest_vert_str, highest_vert_class, x, y, all_vertebrae = [\"l1\", \"l2\", \"l3\", \"l4\", \"l5\", \"s1\"]):\n",
    "    vertebrae_val = {v: 0 for v in all_vertebrae}\n",
    "    #Find the highest vertebrae to act as a reference point within the image, as to what vertebrae are present and their class number.\n",
    "    vert_val = find_vert_with_coords(mask, x, y)\n",
    "    if vert_val == None:\n",
    "        return None\n",
    "    #Align this with order now.\n",
    "    vert_val_dict = align_verts_to_val(highest_vert_str, vert_val)\n",
    "    return vert_val_dict\n",
    "\n",
    "def calculate_disc_bboxes(regions):\n",
    "    #Unpack lx and lx+1 vert bboxes.\n",
    "    bboxes = []\n",
    "    for i in range(len(regions) - 1):\n",
    "        top_u, left_u, bottom_u, right_u = regions[i] #Box above.\n",
    "        top_l, left_l, bottom_l, right_l = regions[i + 1] #Box below.\n",
    "        #Choose largest out of the x values, so nothing is missed.\n",
    "        bbox = bottom_u - 3, min(left_u, left_l), top_l + 3, max(right_u + 5, right_l + 5) #Add some height to the bbox to fill dead space created otherwise.\n",
    "        bboxes.append(bbox)\n",
    "    return bboxes\n",
    "\n",
    "def label_sag_mask(path, mask, chunk, classes, class_numbers_verts):    \n",
    "    chunk = chunk.sort_values(\"level\").reset_index() #Sort down l1_l2 -> l5_s1.\n",
    "    x, y, level = chunk.x[0], chunk.y[0], chunk.level\n",
    "    highest_disc = level[0]\n",
    "    condition = chunk[\"condition\"].values[0]\n",
    "    highest_vert_str, highest_vert_class = disc_to_vert_and_class(highest_disc, condition)\n",
    "\n",
    "    vert_val_dict = locate_vertebrae(mask, highest_vert_str, highest_vert_class, x, y) #Use these values to switch the values on the color mask to their respective class values.\n",
    "    if vert_val_dict is None:\n",
    "        #print(\"vert_val_dict is None.\")\n",
    "        return None\n",
    "    for idx, vert_val in enumerate(vert_val_dict.values()):\n",
    "        mask[mask == vert_val] = class_numbers_verts[idx] #Won't line up due to them being about 20-30 difference.\n",
    "    #Assign all values but class_numbers and 0 to be a 1 (other_disc class).\n",
    "\n",
    "    class_mask = mask.copy().astype(int)\n",
    "    acceptable_vals = class_numbers_verts + [0]\n",
    "    filter_mask = ~np.isin(class_mask, acceptable_vals) #Makes all other detected islands of pixels as a default value.\n",
    "    class_mask[filter_mask] = 1 #~[0, 1, 32...37]\n",
    "\n",
    "    no_other_mask = class_mask.copy()\n",
    "    no_other_mask[no_other_mask == 1] = 0 #Make a copy of the classly labeled mask and remove the other_discs to simplify finding the disc regions between the vertebrae.\n",
    "    no_other_mask = no_other_mask.astype(int)\n",
    "    debug = np.unique(no_other_mask.copy())\n",
    "    no_verts = len(np.unique(no_other_mask)) - 1\n",
    "    regions = []\n",
    "    for i in np.unique(no_other_mask):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        temp_mask = np.where(no_other_mask == i, i, 0)\n",
    "        region = regionprops(temp_mask)\n",
    "        regions.append(region[0].bbox)\n",
    "    disc_bboxes = calculate_disc_bboxes(regions)\n",
    "\n",
    "    #Using the class numbers and the bounding boxes, fill the class mask.\n",
    "    class_numbers = chunk[\"class_number\"].to_list() #Will be the values to assign the discs to (top down).\n",
    "    def_discs = [2, 3, 4, 5, 6]\n",
    "    if \"right\" in condition:\n",
    "        def_discs = list(np.array(def_discs) + 15)\n",
    "\n",
    "    all_discs = {\"l1_l2\": 0, \"l2_l3\": 0, \"l3_l4\": 0, \"l4_l5\": 0, \"l5_s1\": 0}\n",
    "    for idx, disc in enumerate(all_discs.keys()):\n",
    "        disc_info = chunk[chunk[\"level\"] == disc]\n",
    "        if disc_info.empty:\n",
    "            all_discs[disc] = def_discs[idx]\n",
    "        else:\n",
    "            all_discs[disc] = class_numbers[0]\n",
    "            class_numbers.remove(class_numbers[0])\n",
    "\n",
    "    passive_mask = np.zeros_like(class_mask)\n",
    "    class_numbers_padded = list(all_discs.values())\n",
    "    for idx, bbox in enumerate(disc_bboxes):\n",
    "        bottom, left, top, right = bbox\n",
    "        passive_mask[bottom:top, left:right] = class_numbers_padded[idx]\n",
    "    merged_mask = np.where(class_mask > 0, class_mask, passive_mask)                                #no_discs = no_vertebrae - 1.\n",
    "    if 2 * no_verts - 3 != len(np.unique(merged_mask)) - 2: #Must follow the equation no_vertebrae + no_discs - classes[0, 1] == unique - classes[0, 1].\n",
    "        return merged_mask\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def save_mask_as_png(mask, fname):\n",
    "    assert mask.shape == (224, 224)\n",
    "    fname = fname.replace(\"nnUNet_segments\", \"nnUNet_segments_labeled\").replace(\"npy\", \"png\")\n",
    "    save_folder = \"/\".join(fname.split('/')[:-1])\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    mask = mask.astype(np.uint8)\n",
    "    mask_pil = Image.fromarray(mask)\n",
    "    mask_pil.save(fname)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling 8282 Sagittal T1 MRIs.\n",
      "{'Successful': 2980, 'Fail to load': 1852, 'Fail within loop': 3450}\n"
     ]
    }
   ],
   "source": [
    "fail_rates = {\"Successful\": 0, \"Fail to load\": 0, \"Fail within loop\": 0}\n",
    "print(f\"Labeling {len(st1_class_df.groupby([\"series_id\", \"instance_number\"]))} Sagittal T1 MRIs.\")\n",
    "\n",
    "for idx, chunk in st1_class_df.groupby([\"series_id\", \"instance_number\"]):\n",
    "    segment_path = os.path.join(\"nnUNet_segments\", str(chunk[\"study_id\"].values[0]),\n",
    "                                 str(chunk[\"series_id\"].values[0]), f\"{chunk[\"instance_number\"].values[0]}.npy\") \n",
    "    if os.path.isfile(segment_path):\n",
    "        gray_mask = np.load(segment_path) #Is grayscale img.\n",
    "    else:\n",
    "        fail_rates[\"Fail to load\"] = fail_rates[\"Fail to load\"] + 1\n",
    "        continue\n",
    "    color_mask = auto_label_and_correct_mask(gray_mask, st1_classes)\n",
    "    png_path = segment_path.replace(\"npy\", \"png\").replace(\"nnUNet_segments\", \"train_png\")\n",
    "    sag_t1_mask = label_sag_mask(path = png_path, mask = color_mask, chunk = chunk, classes = st1_classes, \n",
    "                                    class_numbers_verts = [32, 33, 34, 35, 36, 37])\n",
    "    if sag_t1_mask is not None:\n",
    "        fail_rates[\"Successful\"] = fail_rates[\"Successful\"] + 1\n",
    "        save_mask_as_png(sag_t1_mask, segment_path)\n",
    "    else:\n",
    "        fail_rates[\"Fail within loop\"] = fail_rates[\"Fail within loop\"] + 1\n",
    "print(fail_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling 2521 Sagittal T2 MRIs.\n",
      "{'Successful': 1869, 'Fail to load': 115, 'Fail within loop': 537}\n",
      "Total number of Sagittal Samples: 4849\n"
     ]
    }
   ],
   "source": [
    "fail_rates = {\"Successful\": 0, \"Fail to load\": 0, \"Fail within loop\": 0}\n",
    "print(f\"Labeling {len(st2_class_df.groupby([\"series_id\", \"instance_number\"]))} Sagittal T2 MRIs.\")\n",
    "for idx, chunk in st2_class_df.groupby([\"series_id\", \"instance_number\"]):\n",
    "    segment_path = os.path.join(\"nnUNet_segments\", str(chunk[\"study_id\"].values[0]),\n",
    "                                str(chunk[\"series_id\"].values[0]), f\"{chunk[\"instance_number\"].values[0]}.npy\")\n",
    "    if os.path.isfile(segment_path):\n",
    "        gray_mask = np.load(segment_path)\n",
    "    else:\n",
    "        fail_rates[\"Fail to load\"] = fail_rates[\"Fail to load\"] + 1\n",
    "        continue\n",
    "    color_mask = auto_label_and_correct_mask(gray_mask, st2_classes)\n",
    "    png_path = segment_path.replace(\"npy\", \"png\").replace(\"nnUNet_segments\", \"train_png\")\n",
    "    sag_t2_mask = label_sag_mask(path = png_path, mask = color_mask, chunk = chunk, classes = st2_classes, \n",
    "                                    class_numbers_verts = [17, 18, 19, 20, 21, 22])\n",
    "    if sag_t2_mask is not None:\n",
    "        fail_rates[\"Successful\"] = fail_rates[\"Successful\"] + 1\n",
    "        save_mask_as_png(sag_t2_mask, segment_path)\n",
    "    else:\n",
    "        fail_rates[\"Fail within loop\"] = fail_rates[\"Fail within loop\"] + 1\n",
    "print(fail_rates)\n",
    "print(f\"Total number of Sagittal Samples: {len(glob(os.path.join(\"nnUNet_segments_labeled\", \"*/*/*png\")))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_info(path):\n",
    "    \"\"\"Takes a path in the style that RSNA use.\"\"\"\n",
    "    sp = path.split('/')\n",
    "    return sp[-3], sp[-2], sp[-1].split('.')[0] #Study_id, series_id, instance_number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ST1 Pairs: 583 \n",
      "ST2 Pairs: 253\n",
      "ST1 Triplets: 54 \n",
      "ST2 Triplets: 19\n"
     ]
    }
   ],
   "source": [
    "\"\"\"2.5D approach\"\"\"\n",
    "#First check the number of 2 adjacent slices within the data.\n",
    "t1_pairs, t1_triplets, t2_pairs, t2_triplets = [], [], [], []\n",
    "for study_id in os.listdir(\"nnUNet_segments_labeled\"):\n",
    "    folder_path = os.path.join(\"nnUNet_segments_labeled\", study_id)\n",
    "    for series_id in os.listdir(folder_path):\n",
    "        #Sagittal T1 or Sagittal T2/STIR\n",
    "        sd = train_series_descriptions[train_series_descriptions[\"series_id\"] == int(series_id)][\"series_description\"].values[0]\n",
    "        series_path = os.path.join(folder_path, series_id)\n",
    "        filenames = os.listdir(series_path)\n",
    "        filenames = [int(filename.removesuffix('.png')) for filename in filenames]\n",
    "        for instance in filenames:\n",
    "            if (instance + 1) in filenames and (instance + 2) in filenames:\n",
    "                if sd == \"Sagittal T1\":\n",
    "                    t1_triplets.extend([os.path.join(series_path, f\"{instance}.png\"), os.path.join(series_path, f\"{instance + 1}.png\")])\n",
    "                elif sd == \"Sagittal T2/STIR\":\n",
    "                    t2_triplets.extend([os.path.join(series_path, f\"{instance}.png\"), os.path.join(series_path, f\"{instance + 1}.png\")])\n",
    "            elif (instance + 1) in filenames:\n",
    "                if sd == \"Sagittal T1\":\n",
    "                    t1_pairs.extend([os.path.join(series_path, f\"{instance}.png\"), os.path.join(series_path, f\"{instance + 1}.png\")])\n",
    "                elif sd == \"Sagittal T2/STIR\":\n",
    "                    t2_pairs.extend([os.path.join(series_path, f\"{instance}.png\"), os.path.join(series_path, f\"{instance + 1}.png\")])\n",
    "\n",
    "print(f\"ST1 Pairs: {len(t1_pairs) // 2} \\nST2 Pairs: {len(t2_pairs) // 2}\") #As we can see, there are enough pairs but not enought triplets.\n",
    "print(f\"ST1 Triplets: {len(t1_triplets) // 3} \\nST2 Triplets: {len(t2_triplets) // 3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Stack masks and imgs on each other.\"\"\"\n",
    "import nibabel as nib\n",
    "STACKED_ST1_MASKS_DIR = \"nnUNet_raw/Dataset001_ST1_Degeneration/labelsTr\"\n",
    "STACKED_ST1_IMGS_DIR = \"nnUNet_raw/Dataset001_ST1_Degeneration/imagesTr\"\n",
    "STACKED_ST2_MASKS_DIR = \"nnUNet_raw/Dataset002_ST2_Degeneration/labelsTr\"\n",
    "STACKED_ST2_IMGS_DIR = \"nnUNet_raw/Dataset002_ST2_Degeneration/imagesTr\"\n",
    "os.makedirs(STACKED_ST1_MASKS_DIR, exist_ok=True)\n",
    "os.makedirs(STACKED_ST1_IMGS_DIR, exist_ok=True)\n",
    "os.makedirs(STACKED_ST2_MASKS_DIR, exist_ok=True)\n",
    "os.makedirs(STACKED_ST2_IMGS_DIR, exist_ok=True)\n",
    "\n",
    "def stack_arrays(img1, img2):\n",
    "    arr1 = np.array(img1).astype(np.uint8)\n",
    "    arr2 = np.array(img2).astype(np.uint8)\n",
    "    arrd = np.zeros_like(img1).astype(np.uint8)\n",
    "    arr_stacked = np.stack([arr1, arr2, arrd], axis = 1)\n",
    "    return arr_stacked.transpose(0, 2, 1)\n",
    "\n",
    "def save_as_nii(arr, filepath):\n",
    "    nii_image = nib.Nifti1Image(arr, affine=np.eye(4)) #Default affine.\n",
    "    nib.save(nii_image, filepath)   \n",
    "\n",
    "def save_as_png(img, filepath):\n",
    "    #img = (img - np.min(img)) / (np.max(img) - np.min(img)) * 255\n",
    "    img = img.astype(np.uint8)\n",
    "    img = Image.fromarray(img)\n",
    "    img.save(filepath) \n",
    "\n",
    "def process_pair(mask_path1, mask_path2, stacked_mask_dir, stacked_imgs_dir, file_start, idx):\n",
    "    img_path1, img_path2 = mask_path1.replace('nnUNet_segments_labeled', 'train_png'), mask_path2.replace('nnUNet_segments_labeled', 'train_png')\n",
    "\n",
    "    mask1, mask2 = Image.open(mask_path1).convert('L'), Image.open(mask_path2).convert('L')\n",
    "    img1, img2 = Image.open(img_path1).convert('L'), Image.open(img_path2).convert('L')\n",
    "\n",
    "    stacked_mask = stack_arrays(mask1, mask2)\n",
    "    stacked_img = stack_arrays(img1, img2)\n",
    "\n",
    "    new_mask_path = os.path.join(stacked_mask_dir, f\"{file_start}_{f'{idx:04d}'}.png\")\n",
    "    new_img_path = os.path.join(stacked_imgs_dir, f\"{file_start}_{f'{idx:04d}'}_0000.png\")\n",
    "\n",
    "    save_as_png(stacked_mask, new_mask_path)\n",
    "    save_as_png(stacked_img, new_img_path)\n",
    "\n",
    "for i in range(len(t1_pairs) // 2):\n",
    "    back_mask_path, front_mask_path = t1_pairs[2 * i], t1_pairs[2 * i + 1]\n",
    "    process_pair(back_mask_path, front_mask_path, STACKED_ST1_MASKS_DIR, STACKED_ST1_IMGS_DIR, \"ST1\", idx = i)\n",
    "\n",
    "for i in range(len(t2_pairs) // 2):\n",
    "    back_mask_path, front_mask_path = t2_pairs[2 * i], t2_pairs[2 * i + 1]\n",
    "    process_pair(back_mask_path, front_mask_path, STACKED_ST2_MASKS_DIR, STACKED_ST2_IMGS_DIR, \"ST2\", idx = i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Change filenames of train imgs and masks then move to the appropriate folder.\"\"\"\n",
    "def sd_to_bin(sd):\n",
    "    if sd == \"Sagittal T1\": return \"0000\"\n",
    "    if sd == \"Sagittal T2/STIR\": return \"0001\"\n",
    "    if sd == \"Axial T2\": return \"0002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Preprocess test images and rename to format. -> seriesID_instanceNumber_000(0,1,2).png\"\"\"\n",
    "test_img_dir = \"rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939\"\n",
    "save_folders = [\"nnUNet_raw/Dataset001_ST1_Degeneration/imagesTs\", \"axial_test_png\", \"nnUNet_raw/Dataset002_ST2_Degeneration/imagesTs\"]\n",
    "for idx, dicom_folder in enumerate(os.listdir(test_img_dir)):\n",
    "    sd = test_series_description[test_series_description[\"series_id\"] == int(dicom_folder.split('/')[-1])]\n",
    "    sd = sd[\"series_description\"].values[0]\n",
    "    bin_sd = sd_to_bin(sd)\n",
    "    plane = \"sagittal\" if sd != \"Axial T2\" else \"axial\"\n",
    "    dicom_data_3d = load_dicom_stack(os.path.join(test_img_dir, dicom_folder), plane = plane)\n",
    "            \n",
    "    if dicom_data_3d[\"array\"].shape[0] == 0:\n",
    "        print(f\"Dicom data size 0: {dicom_data_3d[\"array\"].shape}\")\n",
    "        continue\n",
    "            \n",
    "    save_folder = save_folders[idx]\n",
    "    os.makedirs(save_folder, exist_ok = True)\n",
    "    #Using 2.5D setup, it is probably best to use 2.5D prediction, this way the model has more context, also that the model sees each important img twice.\n",
    "    for k in range(dicom_data_3d[\"array\"].shape[0] - 1): \n",
    "        img1 = dicom_data_3d[\"array\"][k]\n",
    "        img2 = dicom_data_3d[\"array\"][k + 1]\n",
    "        pixel_spacing = dicom_data_3d[\"pixel_spacing\"]\n",
    "        processed_img1 = preprocess_img(img1, pixel_spacing)\n",
    "        processed_img2 = preprocess_img(img2, pixel_spacing)\n",
    "        nn_img_path = os.path.join(save_folder, f\"ST1_{k:04d}_0000.png\") #{bin_to_sd}\n",
    "        img_stacked = np.stack([processed_img1, processed_img2, np.zeros_like(processed_img1)], axis = 2)\n",
    "        save_as_png(img_stacked, nn_img_path)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1_dataset = {\n",
    "    \"name\": \"Sagittal T1 Degeneration\",\n",
    "    \"description\": \"Using Sagittal T1 images, identify areas of right/left neural foraminal narrowing\",\n",
    "    \"reference\": \"\",\n",
    "    \"licence\": \"\",\n",
    "    \"release\": \"0.0\",\n",
    "    \"tensorImageSize\": \"2D\",\n",
    "\n",
    "    \"channel_names\": { #Input channels into the network.\n",
    "        \"0\": \"slice_n\", \n",
    "        \"1\": \"slice_n+1\",\n",
    "        \"2\": \"zeros_like\",\n",
    "    }, \n",
    "    \"labels\": st1_classes,\n",
    "    \n",
    "    \"numTraining\": len(glob(os.path.join(UNET_ST1_DIR, \"imagesTr\", \"*png\"))), \n",
    "    \"file_ending\": \".png\"\n",
    "    }\n",
    "with open(os.path.join(UNET_ST1_DIR, 'dataset.json'), 'w') as json_file:\n",
    "    json.dump(st1_dataset, json_file, indent=4)\n",
    "\n",
    "st2_dataset = {\n",
    "    \"name\": \"Sagittal T2/STIR Degeneration\",\n",
    "    \"description\": \"Using Sagittal T2/STIR images, identify areas of central spinal canal stenosis\",\n",
    "    \"reference\": \"\",\n",
    "    \"licence\": \"\",\n",
    "    \"release\": \"0.0\",\n",
    "    \"tensorImageSize\": \"2D\",\n",
    "\n",
    "    \"channel_names\": { #Input channels into the network.\n",
    "        \"0\": \"slice_n\", \n",
    "        \"1\": \"slice_n+1\",\n",
    "        \"2\": \"zeros_like\",\n",
    "    }, \n",
    "    \"labels\": st2_classes,\n",
    "    \n",
    "    \"numTraining\": len(glob(os.path.join(UNET_ST2_DIR, \"imagesTr\", \"*png\"))), \n",
    "    \"file_ending\": \".png\"\n",
    "    }\n",
    "with open(os.path.join(UNET_ST2_DIR, 'dataset.json'), 'w') as json_file:\n",
    "    json.dump(st2_dataset, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' #I CAN ACTUALLY JUST PUT ALL OF THIS IN ONE DATASET BUT KEEP SEPARATE FOR NOW DUE TO CONVENIENCE.\\n#Install nnUNet libraries.\\n!pip install nnunetv2\\n\\n#Setup folder directories.\\nexport nnUNet_preprocessed=\"/Users/jakecordery/Desktop/Kaggle Competiton/lumbarSpineDegeneration/nnUNet_preprocessed\"\\nexport nnUNet_results=\"/Users/jakecordery/Desktop/Kaggle Competiton/lumbarSpineDegeneration/nnUNet_results\"\\nexport nnUNet_raw=\"/Users/jakecordery/Desktop/Kaggle Competiton/lumbarSpineDegeneration/nnUNet_raw\"\\n\\n#Plan and preprocess Sagittal T1 and T2.\\nnnUNetv2_plan_and_preprocess -d 001 --verify_dataset_integrity\\nnnUNetv2_plan_and_preprocess -d 002 --verify_dataset_integrity\\n'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" #I CAN ACTUALLY JUST PUT ALL OF THIS IN ONE DATASET BUT KEEP SEPARATE FOR NOW DUE TO CONVENIENCE.\n",
    "#Install nnUNet libraries.\n",
    "!pip install nnunetv2\n",
    "\n",
    "#Setup folder directories.\n",
    "export nnUNet_preprocessed=\"/Users/jakecordery/Desktop/Kaggle Competiton/lumbarSpineDegeneration/nnUNet_preprocessed\"\n",
    "export nnUNet_results=\"/Users/jakecordery/Desktop/Kaggle Competiton/lumbarSpineDegeneration/nnUNet_results\"\n",
    "export nnUNet_raw=\"/Users/jakecordery/Desktop/Kaggle Competiton/lumbarSpineDegeneration/nnUNet_raw\"\n",
    "\n",
    "#Plan and preprocess Sagittal T1 and T2.\n",
    "nnUNetv2_plan_and_preprocess -d 001 --verify_dataset_integrity\n",
    "nnUNetv2_plan_and_preprocess -d 002 --verify_dataset_integrity\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Train and Predict Dataset 001.       (Best dice score found at ~50 epochs)\\nnnUNetv2_train 001 2d 0 -device mps \\nnnUNetv2_predict -i \"/Users/jakecordery/Desktop/Kaggle Competiton/lumbarSpineDegeneration/nnUNet_raw/Dataset001_ST1_Degeneration/imagesTs\" -o \"/Users/jakecordery/Desktop/Kaggle Competiton/lumbarSpineDegeneration/nnUNet_results/output\" -d 001 -c 2d -f 0 --save_probabilities -device mps\\n\\n#Train and Predict Dataset 002.\\nnnUNetv2_train 002 2d 0 -device mps \\nnnUNetv2_predict -i \"/Users/jakecordery/Desktop/Kaggle Competiton/lumbarSpineDegeneration/nnUNet_raw/Dataset002_ST2_Degeneration/imagesTs\" -o \"/Users/jakecordery/Desktop/Kaggle Competiton/lumbarSpineDegeneration/nnUNet_results/output\" -d 002 -c 2d -f 0 --save_probabilities -device mps\\n'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#Train and Predict Dataset 001.       (Best dice score found at ~50 epochs)\n",
    "nnUNetv2_train 001 2d 0 -device mps \n",
    "nnUNetv2_predict -i \"/Users/jakecordery/Desktop/Kaggle Competiton/lumbarSpineDegeneration/nnUNet_raw/Dataset001_ST1_Degeneration/imagesTs\" -o \"/Users/jakecordery/Desktop/Kaggle Competiton/lumbarSpineDegeneration/nnUNet_results/output\" -d 001 -c 2d -f 0 --save_probabilities -device mps\n",
    "\n",
    "#Train and Predict Dataset 002.\n",
    "nnUNetv2_train 002 2d 0 -device mps \n",
    "nnUNetv2_predict -i \"/Users/jakecordery/Desktop/Kaggle Competiton/lumbarSpineDegeneration/nnUNet_raw/Dataset002_ST2_Degeneration/imagesTs\" -o \"/Users/jakecordery/Desktop/Kaggle Competiton/lumbarSpineDegeneration/nnUNet_results/output\" -d 002 -c 2d -f 0 --save_probabilities -device mps\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Visualize predictions on the test data.\"\"\"\n",
    "ST1_PREDICTIONS_OUTPUT = \"nnUNet_results/output\"\n",
    "ST2_PREDICTIONS_OUTPUT = \"nnUNet_results/output\"\n",
    "for idx, path in enumerate(list(sorted(glob(os.path.join(ST2_PREDICTIONS_OUTPUT, \"*png\"))))):\n",
    "    data = nib.load(path)\n",
    "    test_path = path.replace(\"nnUNet_results\", \"nnUNet_raw/Dataset002_ST2_Degeneration\").replace(\"output\", \"imagesTs\")\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    ax1.imshow(nib.load(test_path))\n",
    "    ax2.imshow(data)\n",
    "    plt.show()\n",
    "\n",
    "    #logits_mask = data[\"probabilities\"] #This contains a (class_number, 1, 224, 224) of (raw?) logits.\n",
    "    #print(f\"Prediction {idx}:\\nshape: {logits_mask.shape}\\nmax value: {np.max(logits_mask)}\\nmin value: {np.min(logits_mask)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Work out the probabilites using the logit masks.\"\"\"\n",
    "sag_t1_groups = {\n",
    "    \"left_neural_foraminal_narrowing_l1_l2\": {2: 0, 7: 0, 12: 0}, #Condition and their class_numbers.\n",
    "    \"left_neural_foraminal_narrowing_l2_l3\": {3: 0, 8: 0, 13: 0},\n",
    "    \"left_neural_foraminal_narrowing_l3_l4\": {4: 0, 9: 0, 14: 0},\n",
    "    \"left_neural_foraminal_narrowing_l4_l5\": {5: 0, 10: 0, 15: 0},\n",
    "    \"left_neural_foraminal_narrowing_l5_s1\": {6: 0, 11: 0, 16: 0},\n",
    "\n",
    "    \"right_neural_foraminal_narrowing_l1_l2\": {17: 0, 22: 0, 27: 0},\n",
    "    \"right_neural_foraminal_narrowing_l2_l3\": {18: 0, 23: 0, 28: 0},\n",
    "    \"right_neural_foraminal_narrowing_l3_l4\": {19: 0, 24: 0, 29: 0},\n",
    "    \"right_neural_foraminal_narrowing_l4_l5\": {20: 0, 25: 0, 30: 0},\n",
    "    \"right_neural_foraminal_narrowing_l5_s1\": {21: 0, 26: 0, 31: 0},\n",
    "}\n",
    "\n",
    "sag_t2_groups = {\n",
    "    \"spinal_canal_stenosis_l1_l2\": {2: 0, 7: 0, 12: 0}, #Condition and their class_numbers.\n",
    "    \"spinal_canal_stenosis_l2_l3\": {3: 0, 8: 0, 13: 0},\n",
    "    \"spinal_canal_stenosis_l3_l4\": {4: 0, 9: 0, 14: 0},\n",
    "    \"spinal_canal_stenosis_l4_l5\": {5: 0, 10: 0, 15: 0},\n",
    "    \"spinal_canal_stenosis_l5_s1\": {6: 0, 11: 0, 16: 0},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_logits(raw_logits, s, condition):\n",
    "    #Drop irrelevant logit (0th) dimensions.\n",
    "    #print(f\"raw logits shape {raw_logits.shape}\")\n",
    "    relevant_logits = raw_logits[s].reshape(5, 1, 3, 224, 224)\n",
    "    #print(f\"relevant logits shape: {relevant_logits.shape}\")\n",
    "    \n",
    "    summed_mask_faces = np.sum(relevant_logits, axis = (-1, -2))\n",
    "    print(f\"summed_mask_faces shape: {summed_mask_faces.shape}\")\n",
    "\n",
    "    if condition == \"narrowing\":\n",
    "        summed_mask_faces = summed_mask_faces.reshape(5, 2, 3)\n",
    "        #Determine right or left by the sum of the logits in each 1st dimensional slice. (Left is slice [:, 0])\n",
    "        lmask = np.sum(summed_mask_faces[:, 0], axis = 1) \n",
    "        rmask = np.sum(summed_mask_faces[:, 1], axis = 1)\n",
    "        if np.sum(rmask) > np.sum(lmask):\n",
    "            summed_mask_faces[:, 0] = 0 \n",
    "        else:\n",
    "            summed_mask_faces[:, 1] = 0\n",
    "    else:\n",
    "        summed_mask_faces.reshape(5, 1, 3)\n",
    "        \n",
    "    #Softmax each set of 3 logits.\n",
    "    probabilities = np.array(F.softmax(torch.tensor(summed_mask_faces), dim = 0))\n",
    "    print(f\"probs shape: {probabilities.shape}\")\n",
    "    print(f\"example of SM probs: {probabilities[0]}\")\n",
    "    return probabilities\n",
    "\n",
    "def vertebrae_to_confidence(logits, mask):\n",
    "    vertebrae_logits = logits[mask]\n",
    "    vert_pix_count = np.sum(np.where(vertebrae_logits > 0))\n",
    "    if vert_pix_count > 5500:\n",
    "        return 1\n",
    "    elif vert_pix_count < 5500:\n",
    "        return vert_pix_count / 5500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Patient-wide probabilites, but first -> Unpack the 2.5D predictions into 2 2D images.\"\"\"\n",
    "def process_raw_outputs(mask_groups, predictions_output_path, p_mask, vert_mask, p_sum, condition, confidences = []):\n",
    "    for s in mask_groups.values():\n",
    "        for path in list(sorted(glob(os.path.join(predictions_output_path, \"*npz\")))):\n",
    "            data = np.load(path)\n",
    "            logits = data[\"probabilities\"] #Shape: (no_classes, 2, 224, 224).\n",
    "            for dimension in range(logits.shape[1]): #Loop over each of the stacked masks.\n",
    "                probabilities = process_logits(logits[:, dimension], s, p_mask, condition)\n",
    "                #mask_confidence = vertebrae_to_confidence(logits[:, dimension], vert_mask) #Remove confidence value for now, to simplify.\n",
    "                p_sum = p_sum + probabilities # * mask_confidence\n",
    "                #confidences.append(mask_confidence)\n",
    "    p_avg = p_sum / len(glob(os.path.join(predictions_output_path, \"*npz\")))\n",
    "    return p_avg\n",
    "\n",
    "#st1_severity = process_raw_outputs(ST1_PREDICTIONS_OUTPUT, p_mask = list(range(2, 31, 1)), vert_mask = list(range(32, 37, 1)))\n",
    "\n",
    "st2_severity = process_raw_outputs(sag_t2_groups, \n",
    "                                   ST2_PREDICTIONS_OUTPUT, \n",
    "                                   p_mask = list(range(2, 17, 1)), \n",
    "                                   vert_mask = list(range(17, 23, 1)),\n",
    "                                   p_sum = np.zeros((5, 3)), \n",
    "                                   condition = \"canal_stenosis\")\n",
    "print(st2_severity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################################\n",
    "######################################################## AXIAL PREDICTIONS #####################################################################\n",
    "################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Convert 2D pngs into 3D'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Convert 2D pngs into 3D\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ax_sds = train_series_descriptions[train_series_descriptions[\"series_description\"] == \"Axial T2\"]\\nfilepaths = rtrain[0].apply(study_to_fpath)'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Slice the train df and convert the severities into binary arrays.\"\"\"\n",
    "rtrain = train[train.columns[16:]].copy()\n",
    "def sev_to_bin(sev):\n",
    "    if sev == \"Normal/Mild\": return [1, 0, 0]\n",
    "    elif sev == \"Moderate\": return [0, 1, 0]\n",
    "    elif sev == \"Severe\": return [0, 0, 1]\n",
    "\n",
    "\"\"\"def study_to_fpath(st):\n",
    "    rdf = ax_sds[ax_sds[\"study_id\" == int(st)]]\n",
    "    si = rdf[\"series_id\"].values[0]\n",
    "    filepath = os.path.join(str(st), str(si), f\"0.npy\")\"\"\"\n",
    "\n",
    "\n",
    "for col in rtrain.columns[1:]:\n",
    "    rtrain[col] = rtrain[col].apply(sev_to_bin)\n",
    "\n",
    "\"\"\"ax_sds = train_series_descriptions[train_series_descriptions[\"series_description\"] == \"Axial T2\"]\n",
    "filepaths = rtrain[0].apply(study_to_fpath)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 17\u001b[0m\n\u001b[1;32m      9\u001b[0m ax_severity \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m3\u001b[39m)) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     11\u001b[0m zipped_severities \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([st1_severity[:\u001b[38;5;241m5\u001b[39m],\n\u001b[1;32m     12\u001b[0m                               ax_severity[:\u001b[38;5;241m5\u001b[39m],\n\u001b[1;32m     13\u001b[0m                               st1_severity[\u001b[38;5;241m5\u001b[39m:],\n\u001b[1;32m     14\u001b[0m                               ax_severity[\u001b[38;5;241m5\u001b[39m:],\n\u001b[1;32m     15\u001b[0m                               st2_severity])\n\u001b[0;32m---> 17\u001b[0m submission \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrow_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnormal_mild\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mzipped_severities\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmoderate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mzipped_severities\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msevere\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mzipped_severities\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/internals/construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "\"\"\"Insert severities into renamed sample_submission.csv\"\"\"\n",
    "sub_temp = pd.read_csv(\"rsna-2024-lumbar-spine-degenerative-classification/sample_submission.csv\")\n",
    "submission_columns = sub_temp.columns\n",
    "#Copy the first column of the submission. Structure -> left_foraminal, left_subarticular, right_for, right_sub, canal_stenosis (25 rows).\n",
    "col1 = sub_temp[\"row_id\"].to_list()\n",
    "\n",
    "#Temporary Solution: default axial severities -> [0.33..., 0.33..., 0.33...] x 10 rows.\n",
    "st1_severity = np.ones((10, 3)) * (1 / 3)\n",
    "ax_severity = np.ones((10, 3)) * (1 / 3)\n",
    "\n",
    "zipped_severities = np.array([st1_severity[:5],\n",
    "                              ax_severity[:5],\n",
    "                              st1_severity[5:],\n",
    "                              ax_severity[5:],\n",
    "                              st2_severity])\n",
    "\n",
    "submission = pd.DataFrame({\"row_id\": col1, \n",
    "                           \"normal_mild\": zipped_severities[0].flatten(), \n",
    "                           \"moderate\": zipped_severities[1].flatten(), \n",
    "                           \"severe\": zipped_severities[2].flatten()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"testing zone. keep clear.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
